{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>종가_ex</th>\n",
       "      <th>1Y_대비_irs</th>\n",
       "      <th>10Y_대비_irs</th>\n",
       "      <th>1Y_대비_crs</th>\n",
       "      <th>대비_국고10년</th>\n",
       "      <th>대비_ndf</th>\n",
       "      <th>전일종가_ex</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DateTime</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2012-08-02</th>\n",
       "      <td>1131.7</td>\n",
       "      <td>-0.03</td>\n",
       "      <td>-0.05</td>\n",
       "      <td>-0.01</td>\n",
       "      <td>-0.04</td>\n",
       "      <td>1.75</td>\n",
       "      <td>1126.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2012-08-03</th>\n",
       "      <td>1134.8</td>\n",
       "      <td>-0.03</td>\n",
       "      <td>-0.02</td>\n",
       "      <td>-0.01</td>\n",
       "      <td>-0.07</td>\n",
       "      <td>4.00</td>\n",
       "      <td>1131.7</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             종가_ex  1Y_대비_irs  10Y_대비_irs  1Y_대비_crs  대비_국고10년  대비_ndf  \\\n",
       "DateTime                                                                 \n",
       "2012-08-02  1131.7      -0.03       -0.05      -0.01     -0.04    1.75   \n",
       "2012-08-03  1134.8      -0.03       -0.02      -0.01     -0.07    4.00   \n",
       "\n",
       "            전일종가_ex  \n",
       "DateTime             \n",
       "2012-08-02   1126.5  \n",
       "2012-08-03   1131.7  "
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import warnings \n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# 파일 불러오기\n",
    "all = pd.read_excel(\"../엑셀/Join_data.xlsx\", index_col = 0)    \n",
    "\n",
    "# 컬럼 추출\n",
    "all2 = all[['DateTime', '종가_ex','1Y_전일비_irs', '2Y_전일비_irs', '3Y_전일비_irs',\n",
    "        '5Y_전일비_irs', '10Y_전일비_irs',  '1Y_전일비_crs', '2Y_전일비_crs','3Y_전일비_crs','5Y_전일비_crs','10Y_전일비_crs',\n",
    "        '국고1년', '국고3년', '국고5년','국고10년', '통안364일', '통안2년', 'Mid_ndf',\n",
    "        'M1_스왑포인트']]            # [[]] 대괄호 2개 사용 -> 데이터 프레임형태로 나옴\n",
    "\n",
    "all2 = all2.set_index(\"DateTime\")\n",
    "\n",
    "all2['대비_국고1년'] = all2['국고1년']-all2['국고1년'].shift(1)\n",
    "all2['대비_국고3년'] = all2['국고3년']-all2['국고3년'].shift(1)\n",
    "all2['대비_국고5년'] = all2['국고5년']-all2['국고5년'].shift(1)\n",
    "all2['대비_국고10년'] = all2['국고10년']-all2['국고10년'].shift(1)\n",
    "all2['대비_통안1년'] = all2['통안364일']-all2['통안364일'].shift(1)\n",
    "all2['대비_통안2년'] = all2['통안364일']-all2['통안364일'].shift(1)\n",
    "all2['대비_ndf'] = all2['Mid_ndf']-all2['Mid_ndf'].shift(1)\n",
    "all2['스왑포인트_1월물'] = all2[\"M1_스왑포인트\"]/100 \n",
    "all2['전일종가_ex'] = all2['종가_ex'].shift(1)\n",
    "\n",
    "all2.rename({\"1Y_전일비_irs\" : \"1Y_대비_irs\", \"2Y_전일비_irs\" : \"2Y_대비_irs\", \"3Y_전일비_irs\" : \"3Y_대비_irs\", \"5Y_전일비_irs\" : \"5Y_대비_irs\", \"10Y_전일비_irs\" : \"10Y_대비_irs\",\n",
    "            \"1Y_전일비_crs\" : \"1Y_대비_crs\", \"2Y_전일비_crs\" : \"2Y_대비_crs\", \"3Y_전일비_crs\" : \"3Y_대비_crs\", \"5Y_전일비_crs\" : \"5Y_대비_crs\", \"10Y_전일비_crs\" : \"10Y_대비_crs\"}, axis=1, inplace=True)\n",
    "\n",
    "all2 = all2.dropna()\n",
    "\n",
    "# 필요 칼럼만 남기기\n",
    "df = all2.copy()\n",
    "df = all2[[\"종가_ex\", \n",
    "            '1Y_대비_irs', '10Y_대비_irs', \n",
    "            '1Y_대비_crs',\n",
    "            \"대비_국고10년\",\n",
    "            \"대비_ndf\", \"전일종가_ex\"]]\n",
    "\n",
    "# DateTime을 인덱스로 바꿔주기\n",
    "df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>1Y_대비_irs</th>\n",
       "      <th>10Y_대비_irs</th>\n",
       "      <th>1Y_대비_crs</th>\n",
       "      <th>대비_국고10년</th>\n",
       "      <th>대비_ndf</th>\n",
       "      <th>전일종가_ex</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DateTime</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2012-08-02</th>\n",
       "      <td>-0.847862</td>\n",
       "      <td>-1.009126</td>\n",
       "      <td>-0.205336</td>\n",
       "      <td>-1.027569</td>\n",
       "      <td>0.079167</td>\n",
       "      <td>-0.149841</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2012-08-03</th>\n",
       "      <td>-0.847862</td>\n",
       "      <td>-0.403231</td>\n",
       "      <td>-0.205336</td>\n",
       "      <td>-1.798403</td>\n",
       "      <td>0.184972</td>\n",
       "      <td>-0.056232</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2012-08-06</th>\n",
       "      <td>0.560374</td>\n",
       "      <td>0.202663</td>\n",
       "      <td>-0.003044</td>\n",
       "      <td>0.000209</td>\n",
       "      <td>-0.449862</td>\n",
       "      <td>-0.000426</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2012-08-07</th>\n",
       "      <td>0.278727</td>\n",
       "      <td>0.404628</td>\n",
       "      <td>0.401540</td>\n",
       "      <td>0.000209</td>\n",
       "      <td>0.020386</td>\n",
       "      <td>-0.104837</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2012-08-08</th>\n",
       "      <td>0.278727</td>\n",
       "      <td>0.606592</td>\n",
       "      <td>0.199248</td>\n",
       "      <td>-0.513680</td>\n",
       "      <td>0.055654</td>\n",
       "      <td>-0.108437</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-07-25</th>\n",
       "      <td>-1.129510</td>\n",
       "      <td>-2.220914</td>\n",
       "      <td>-1.621379</td>\n",
       "      <td>-2.312292</td>\n",
       "      <td>0.154406</td>\n",
       "      <td>3.207485</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-07-26</th>\n",
       "      <td>-0.284568</td>\n",
       "      <td>-0.605196</td>\n",
       "      <td>0.199248</td>\n",
       "      <td>-0.770625</td>\n",
       "      <td>0.050952</td>\n",
       "      <td>3.220086</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-07-27</th>\n",
       "      <td>-0.284568</td>\n",
       "      <td>-1.211091</td>\n",
       "      <td>0.199248</td>\n",
       "      <td>-1.541458</td>\n",
       "      <td>-0.026639</td>\n",
       "      <td>3.110275</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-07-28</th>\n",
       "      <td>0.842021</td>\n",
       "      <td>1.414452</td>\n",
       "      <td>0.806124</td>\n",
       "      <td>2.055766</td>\n",
       "      <td>-0.214738</td>\n",
       "      <td>3.212885</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-07-29</th>\n",
       "      <td>-1.974451</td>\n",
       "      <td>-2.422879</td>\n",
       "      <td>-2.228254</td>\n",
       "      <td>-2.055348</td>\n",
       "      <td>-0.485131</td>\n",
       "      <td>2.903255</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2459 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            1Y_대비_irs  10Y_대비_irs  1Y_대비_crs  대비_국고10년    대비_ndf   전일종가_ex\n",
       "DateTime                                                                  \n",
       "2012-08-02  -0.847862   -1.009126  -0.205336 -1.027569  0.079167 -0.149841\n",
       "2012-08-03  -0.847862   -0.403231  -0.205336 -1.798403  0.184972 -0.056232\n",
       "2012-08-06   0.560374    0.202663  -0.003044  0.000209 -0.449862 -0.000426\n",
       "2012-08-07   0.278727    0.404628   0.401540  0.000209  0.020386 -0.104837\n",
       "2012-08-08   0.278727    0.606592   0.199248 -0.513680  0.055654 -0.108437\n",
       "...               ...         ...        ...       ...       ...       ...\n",
       "2022-07-25  -1.129510   -2.220914  -1.621379 -2.312292  0.154406  3.207485\n",
       "2022-07-26  -0.284568   -0.605196   0.199248 -0.770625  0.050952  3.220086\n",
       "2022-07-27  -0.284568   -1.211091   0.199248 -1.541458 -0.026639  3.110275\n",
       "2022-07-28   0.842021    1.414452   0.806124  2.055766 -0.214738  3.212885\n",
       "2022-07-29  -1.974451   -2.422879  -2.228254 -2.055348 -0.485131  2.903255\n",
       "\n",
       "[2459 rows x 6 columns]"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# 쓸 칼럼만 남기고 feature, target 분리해 각각 x,y 에 저장\n",
    "x = df[['1Y_대비_irs', '10Y_대비_irs',  \n",
    "            '1Y_대비_crs',\n",
    "            \"대비_국고10년\",\n",
    "            \"대비_ndf\", \"전일종가_ex\"]]\n",
    "y = df[[\"종가_ex\"]]\n",
    "\n",
    "# 이건 이렇게 해야 밑에 코드 8번째 줄 columns에 들어갈 수 있다고 하네요!\n",
    "x.feature = x.columns \n",
    "x.feature\n",
    "\n",
    "# scaling 진행\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# MinMaxScaler객체 생성\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# MinMaxScaler 로 데이터 셋 변환. fit() 과 transform() 호출.\n",
    "scaler.fit(x)\n",
    "data_scaled = scaler.transform(x)\n",
    "\n",
    "# transform()시 scale 변환된 데이터 셋이 numpy ndarry로 반환되어 이를 DataFrame으로 변환\n",
    "x_scaled = pd.DataFrame(data = data_scaled, columns=x.feature)\n",
    "x_scaled.index = y.index # 인덱스가 달라서 똑같이 설정\n",
    "\n",
    "x_scaled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>1Y_대비_irs</th>\n",
       "      <th>10Y_대비_irs</th>\n",
       "      <th>1Y_대비_crs</th>\n",
       "      <th>대비_국고10년</th>\n",
       "      <th>대비_ndf</th>\n",
       "      <th>전일종가_ex</th>\n",
       "      <th>종가_ex</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DateTime</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2012-08-02</th>\n",
       "      <td>-0.847862</td>\n",
       "      <td>-1.009126</td>\n",
       "      <td>-0.205336</td>\n",
       "      <td>-1.027569</td>\n",
       "      <td>0.079167</td>\n",
       "      <td>-0.149841</td>\n",
       "      <td>1131.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2012-08-03</th>\n",
       "      <td>-0.847862</td>\n",
       "      <td>-0.403231</td>\n",
       "      <td>-0.205336</td>\n",
       "      <td>-1.798403</td>\n",
       "      <td>0.184972</td>\n",
       "      <td>-0.056232</td>\n",
       "      <td>1134.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2012-08-06</th>\n",
       "      <td>0.560374</td>\n",
       "      <td>0.202663</td>\n",
       "      <td>-0.003044</td>\n",
       "      <td>0.000209</td>\n",
       "      <td>-0.449862</td>\n",
       "      <td>-0.000426</td>\n",
       "      <td>1129.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2012-08-07</th>\n",
       "      <td>0.278727</td>\n",
       "      <td>0.404628</td>\n",
       "      <td>0.401540</td>\n",
       "      <td>0.000209</td>\n",
       "      <td>0.020386</td>\n",
       "      <td>-0.104837</td>\n",
       "      <td>1128.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2012-08-08</th>\n",
       "      <td>0.278727</td>\n",
       "      <td>0.606592</td>\n",
       "      <td>0.199248</td>\n",
       "      <td>-0.513680</td>\n",
       "      <td>0.055654</td>\n",
       "      <td>-0.108437</td>\n",
       "      <td>1128.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-07-25</th>\n",
       "      <td>-1.129510</td>\n",
       "      <td>-2.220914</td>\n",
       "      <td>-1.621379</td>\n",
       "      <td>-2.312292</td>\n",
       "      <td>0.154406</td>\n",
       "      <td>3.207485</td>\n",
       "      <td>1313.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-07-26</th>\n",
       "      <td>-0.284568</td>\n",
       "      <td>-0.605196</td>\n",
       "      <td>0.199248</td>\n",
       "      <td>-0.770625</td>\n",
       "      <td>0.050952</td>\n",
       "      <td>3.220086</td>\n",
       "      <td>1307.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-07-27</th>\n",
       "      <td>-0.284568</td>\n",
       "      <td>-1.211091</td>\n",
       "      <td>0.199248</td>\n",
       "      <td>-1.541458</td>\n",
       "      <td>-0.026639</td>\n",
       "      <td>3.110275</td>\n",
       "      <td>1313.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-07-28</th>\n",
       "      <td>0.842021</td>\n",
       "      <td>1.414452</td>\n",
       "      <td>0.806124</td>\n",
       "      <td>2.055766</td>\n",
       "      <td>-0.214738</td>\n",
       "      <td>3.212885</td>\n",
       "      <td>1296.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-07-29</th>\n",
       "      <td>-1.974451</td>\n",
       "      <td>-2.422879</td>\n",
       "      <td>-2.228254</td>\n",
       "      <td>-2.055348</td>\n",
       "      <td>-0.485131</td>\n",
       "      <td>2.903255</td>\n",
       "      <td>1299.1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2459 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            1Y_대비_irs  10Y_대비_irs  1Y_대비_crs  대비_국고10년    대비_ndf   전일종가_ex  \\\n",
       "DateTime                                                                     \n",
       "2012-08-02  -0.847862   -1.009126  -0.205336 -1.027569  0.079167 -0.149841   \n",
       "2012-08-03  -0.847862   -0.403231  -0.205336 -1.798403  0.184972 -0.056232   \n",
       "2012-08-06   0.560374    0.202663  -0.003044  0.000209 -0.449862 -0.000426   \n",
       "2012-08-07   0.278727    0.404628   0.401540  0.000209  0.020386 -0.104837   \n",
       "2012-08-08   0.278727    0.606592   0.199248 -0.513680  0.055654 -0.108437   \n",
       "...               ...         ...        ...       ...       ...       ...   \n",
       "2022-07-25  -1.129510   -2.220914  -1.621379 -2.312292  0.154406  3.207485   \n",
       "2022-07-26  -0.284568   -0.605196   0.199248 -0.770625  0.050952  3.220086   \n",
       "2022-07-27  -0.284568   -1.211091   0.199248 -1.541458 -0.026639  3.110275   \n",
       "2022-07-28   0.842021    1.414452   0.806124  2.055766 -0.214738  3.212885   \n",
       "2022-07-29  -1.974451   -2.422879  -2.228254 -2.055348 -0.485131  2.903255   \n",
       "\n",
       "             종가_ex  \n",
       "DateTime            \n",
       "2012-08-02  1131.7  \n",
       "2012-08-03  1134.8  \n",
       "2012-08-06  1129.0  \n",
       "2012-08-07  1128.8  \n",
       "2012-08-08  1128.3  \n",
       "...            ...  \n",
       "2022-07-25  1313.7  \n",
       "2022-07-26  1307.6  \n",
       "2022-07-27  1313.3  \n",
       "2022-07-28  1296.1  \n",
       "2022-07-29  1299.1  \n",
       "\n",
       "[2459 rows x 7 columns]"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_scaled = pd.concat([x_scaled,y], axis=1)\n",
    "df_scaled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = df_scaled[0:1945]\n",
    "test = df_scaled[1945:]\n",
    "\n",
    "def make_dataset(data, label, window_size=1):\n",
    "    feature_list = []\n",
    "    label_list = []\n",
    "    for i in range(len(data) - window_size):\n",
    "        feature_list.append(np.array(data.iloc[i:i+window_size]))\n",
    "        label_list.append(np.array(label.iloc[i+window_size]))\n",
    "    return np.array(feature_list), np.array(label_list)\n",
    "\n",
    "feature_cols = ['1Y_대비_irs', '10Y_대비_irs','1Y_대비_crs', '대비_국고10년', '대비_ndf', '전일종가_ex']\n",
    "label_cols = ['종가_ex']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1555, 1, 6), (389, 1, 6))"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train_feature = train[feature_cols]\n",
    "train_label = train[label_cols]\n",
    "test_feature = test[feature_cols]\n",
    "test_label = test[label_cols]\n",
    "\n",
    "train_feature, train_label = make_dataset(train_feature, train_label, 1)\n",
    "x_train, x_valid, y_train, y_valid = train_test_split(train_feature, train_label, test_size=0.2)\n",
    "x_train.shape, x_valid.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[-2.92070151e-03,  2.02662908e-01,  6.03831686e-01,\n",
       "          2.08982982e-04, -8.07176096e-02, -3.46059980e-01]],\n",
       "\n",
       "       [[-2.84567957e-01, -3.02249039e-01, -2.05335679e-01,\n",
       "         -7.70624745e-01, -2.42878567e-02, -1.14173720e+00]],\n",
       "\n",
       "       [[-2.84567957e-01, -4.03231428e-01,  1.99248003e-01,\n",
       "         -7.70624745e-01, -1.20688685e-01,  6.77426463e-03]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[-2.84567957e-01, -4.03231428e-01,  1.99248003e-01,\n",
       "         -2.56735593e-01, -3.13490340e-01, -2.48850545e-01]],\n",
       "\n",
       "       [[-5.66215212e-01, -2.01266649e-01, -1.01450304e+00,\n",
       "          2.08982982e-04,  6.38761739e-01,  1.44871421e+00]],\n",
       "\n",
       "       [[-5.66215212e-01, -1.00912576e+00, -2.05335679e-01,\n",
       "         -1.28451390e+00,  3.54261735e-01, -8.50346459e-02]]])"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((513, 1, 6), (513, 1))"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_feature, test_label = make_dataset(test_feature, test_label, 1)\n",
    "test_feature.shape, test_label.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "87/98 [=========================>....] - ETA: 0s - loss: 1263055.0000 - mae: 1122.7766\n",
      "Epoch 1: val_loss improved from inf to 1277535.62500, saving model to ./\n",
      "INFO:tensorflow:Assets written to: ./assets\n",
      "98/98 [==============================] - 3s 18ms/step - loss: 1263714.7500 - mae: 1123.0417 - val_loss: 1277535.6250 - val_mae: 1129.0677\n",
      "Epoch 2/200\n",
      "87/98 [=========================>....] - ETA: 0s - loss: 1262898.6250 - mae: 1122.6942\n",
      "Epoch 2: val_loss improved from 1277535.62500 to 1275672.00000, saving model to ./\n",
      "INFO:tensorflow:Assets written to: ./assets\n",
      "98/98 [==============================] - 2s 17ms/step - loss: 1262559.3750 - mae: 1122.5308 - val_loss: 1275672.0000 - val_mae: 1128.2438\n",
      "Epoch 3/200\n",
      "87/98 [=========================>....] - ETA: 0s - loss: 1260508.3750 - mae: 1121.6251\n",
      "Epoch 3: val_loss improved from 1275672.00000 to 1272329.37500, saving model to ./\n",
      "INFO:tensorflow:Assets written to: ./assets\n",
      "98/98 [==============================] - 2s 17ms/step - loss: 1260268.8750 - mae: 1121.5159 - val_loss: 1272329.3750 - val_mae: 1126.7603\n",
      "Epoch 4/200\n",
      "90/98 [==========================>...] - ETA: 0s - loss: 1256359.6250 - mae: 1119.7576\n",
      "Epoch 4: val_loss improved from 1272329.37500 to 1267151.50000, saving model to ./\n",
      "INFO:tensorflow:Assets written to: ./assets\n",
      "98/98 [==============================] - 2s 18ms/step - loss: 1256312.3750 - mae: 1119.7560 - val_loss: 1267151.5000 - val_mae: 1124.4500\n",
      "Epoch 5/200\n",
      "86/98 [=========================>....] - ETA: 0s - loss: 1250068.1250 - mae: 1116.9640\n",
      "Epoch 5: val_loss improved from 1267151.50000 to 1259960.87500, saving model to ./\n",
      "INFO:tensorflow:Assets written to: ./assets\n",
      "98/98 [==============================] - 2s 16ms/step - loss: 1250420.5000 - mae: 1117.1190 - val_loss: 1259960.8750 - val_mae: 1121.2180\n",
      "Epoch 6/200\n",
      "89/98 [==========================>...] - ETA: 0s - loss: 1243266.2500 - mae: 1113.8950\n",
      "Epoch 6: val_loss improved from 1259960.87500 to 1250761.00000, saving model to ./\n",
      "INFO:tensorflow:Assets written to: ./assets\n",
      "98/98 [==============================] - 2s 21ms/step - loss: 1242517.1250 - mae: 1113.5599 - val_loss: 1250761.0000 - val_mae: 1117.0524\n",
      "Epoch 7/200\n",
      "95/98 [============================>.] - ETA: 0s - loss: 1232321.6250 - mae: 1108.9502\n",
      "Epoch 7: val_loss improved from 1250761.00000 to 1240083.87500, saving model to ./\n",
      "INFO:tensorflow:Assets written to: ./assets\n",
      "98/98 [==============================] - 2s 18ms/step - loss: 1232760.1250 - mae: 1109.1434 - val_loss: 1240083.8750 - val_mae: 1112.1799\n",
      "Epoch 8/200\n",
      "79/98 [=======================>......] - ETA: 0s - loss: 1223290.6250 - mae: 1104.8286\n",
      "Epoch 8: val_loss improved from 1240083.87500 to 1227988.87500, saving model to ./\n",
      "INFO:tensorflow:Assets written to: ./assets\n",
      "98/98 [==============================] - 2s 17ms/step - loss: 1221535.0000 - mae: 1104.0133 - val_loss: 1227988.8750 - val_mae: 1106.6213\n",
      "Epoch 9/200\n",
      "72/98 [=====================>........] - ETA: 0s - loss: 1211948.5000 - mae: 1099.6094\n",
      "Epoch 9: val_loss improved from 1227988.87500 to 1214328.62500, saving model to ./\n",
      "INFO:tensorflow:Assets written to: ./assets\n",
      "98/98 [==============================] - 2s 18ms/step - loss: 1208698.6250 - mae: 1098.1211 - val_loss: 1214328.6250 - val_mae: 1100.2795\n",
      "Epoch 10/200\n",
      "83/98 [========================>.....] - ETA: 0s - loss: 1196533.1250 - mae: 1092.4492\n",
      "Epoch 10: val_loss improved from 1214328.62500 to 1199257.37500, saving model to ./\n",
      "INFO:tensorflow:Assets written to: ./assets\n",
      "98/98 [==============================] - 2s 19ms/step - loss: 1194367.3750 - mae: 1091.4606 - val_loss: 1199257.3750 - val_mae: 1093.2036\n",
      "Epoch 11/200\n",
      "87/98 [=========================>....] - ETA: 0s - loss: 1179966.3750 - mae: 1084.6860\n",
      "Epoch 11: val_loss improved from 1199257.37500 to 1182990.37500, saving model to ./\n",
      "INFO:tensorflow:Assets written to: ./assets\n",
      "98/98 [==============================] - 2s 17ms/step - loss: 1178643.6250 - mae: 1084.0985 - val_loss: 1182990.3750 - val_mae: 1085.4772\n",
      "Epoch 12/200\n",
      "82/98 [========================>.....] - ETA: 0s - loss: 1163314.5000 - mae: 1076.8418\n",
      "Epoch 12: val_loss improved from 1182990.37500 to 1165623.75000, saving model to ./\n",
      "INFO:tensorflow:Assets written to: ./assets\n",
      "98/98 [==============================] - 2s 22ms/step - loss: 1161657.2500 - mae: 1076.0813 - val_loss: 1165623.7500 - val_mae: 1077.1310\n",
      "Epoch 13/200\n",
      "95/98 [============================>.] - ETA: 0s - loss: 1143830.2500 - mae: 1067.5392\n",
      "Epoch 13: val_loss improved from 1165623.75000 to 1147207.00000, saving model to ./\n",
      "INFO:tensorflow:Assets written to: ./assets\n",
      "98/98 [==============================] - 2s 16ms/step - loss: 1143551.3750 - mae: 1067.4048 - val_loss: 1147207.0000 - val_mae: 1068.1584\n",
      "Epoch 14/200\n",
      "87/98 [=========================>....] - ETA: 0s - loss: 1126335.5000 - mae: 1059.0752\n",
      "Epoch 14: val_loss improved from 1147207.00000 to 1127998.25000, saving model to ./\n",
      "INFO:tensorflow:Assets written to: ./assets\n",
      "98/98 [==============================] - 2s 16ms/step - loss: 1124407.7500 - mae: 1058.1875 - val_loss: 1127998.2500 - val_mae: 1058.6683\n",
      "Epoch 15/200\n",
      "79/98 [=======================>......] - ETA: 0s - loss: 1108495.2500 - mae: 1050.5941\n",
      "Epoch 15: val_loss improved from 1127998.25000 to 1108128.12500, saving model to ./\n",
      "INFO:tensorflow:Assets written to: ./assets\n",
      "98/98 [==============================] - 2s 17ms/step - loss: 1104521.6250 - mae: 1048.4293 - val_loss: 1108128.1250 - val_mae: 1048.7833\n",
      "Epoch 16/200\n",
      "87/98 [=========================>....] - ETA: 0s - loss: 1084540.0000 - mae: 1038.5145\n",
      "Epoch 16: val_loss improved from 1108128.12500 to 1087696.62500, saving model to ./\n",
      "INFO:tensorflow:Assets written to: ./assets\n",
      "98/98 [==============================] - 2s 17ms/step - loss: 1083864.3750 - mae: 1038.2550 - val_loss: 1087696.6250 - val_mae: 1039.0336\n",
      "Epoch 17/200\n",
      "88/98 [=========================>....] - ETA: 0s - loss: 1064832.5000 - mae: 1028.7228\n",
      "Epoch 17: val_loss improved from 1087696.62500 to 1066632.12500, saving model to ./\n",
      "INFO:tensorflow:Assets written to: ./assets\n",
      "98/98 [==============================] - 2s 16ms/step - loss: 1062529.3750 - mae: 1027.6304 - val_loss: 1066632.1250 - val_mae: 1028.8081\n",
      "Epoch 18/200\n",
      "87/98 [=========================>....] - ETA: 0s - loss: 1042675.6875 - mae: 1017.6120\n",
      "Epoch 18: val_loss improved from 1066632.12500 to 1045230.25000, saving model to ./\n",
      "INFO:tensorflow:Assets written to: ./assets\n",
      "98/98 [==============================] - 2s 21ms/step - loss: 1040634.1250 - mae: 1016.6720 - val_loss: 1045230.2500 - val_mae: 1018.2281\n",
      "Epoch 19/200\n",
      "90/98 [==========================>...] - ETA: 0s - loss: 1019719.3125 - mae: 1006.0757\n",
      "Epoch 19: val_loss improved from 1045230.25000 to 1023427.12500, saving model to ./\n",
      "INFO:tensorflow:Assets written to: ./assets\n",
      "98/98 [==============================] - 1s 15ms/step - loss: 1018264.3125 - mae: 1005.3207 - val_loss: 1023427.1250 - val_mae: 1007.2440\n",
      "Epoch 20/200\n",
      "89/98 [==========================>...] - ETA: 0s - loss: 995069.0625 - mae: 993.3401 \n",
      "Epoch 20: val_loss improved from 1023427.12500 to 1001421.43750, saving model to ./\n",
      "INFO:tensorflow:Assets written to: ./assets\n",
      "98/98 [==============================] - 2s 16ms/step - loss: 995487.1875 - mae: 993.5660 - val_loss: 1001421.4375 - val_mae: 995.9302\n",
      "Epoch 21/200\n",
      "87/98 [=========================>....] - ETA: 0s - loss: 976097.1250 - mae: 983.2027\n",
      "Epoch 21: val_loss improved from 1001421.43750 to 979317.56250, saving model to ./\n",
      "INFO:tensorflow:Assets written to: ./assets\n",
      "98/98 [==============================] - 2s 17ms/step - loss: 972395.3125 - mae: 981.4275 - val_loss: 979317.5625 - val_mae: 984.3444\n",
      "Epoch 22/200\n",
      "87/98 [=========================>....] - ETA: 0s - loss: 950430.2500 - mae: 969.7408\n",
      "Epoch 22: val_loss improved from 979317.56250 to 957072.81250, saving model to ./\n",
      "INFO:tensorflow:Assets written to: ./assets\n",
      "98/98 [==============================] - 2s 17ms/step - loss: 949169.6875 - mae: 969.0782 - val_loss: 957072.8125 - val_mae: 972.4114\n",
      "Epoch 23/200\n",
      "87/98 [=========================>....] - ETA: 0s - loss: 926167.0000 - mae: 956.4892\n",
      "Epoch 23: val_loss improved from 957072.81250 to 934948.62500, saving model to ./\n",
      "INFO:tensorflow:Assets written to: ./assets\n",
      "98/98 [==============================] - 2s 21ms/step - loss: 925790.6875 - mae: 956.3699 - val_loss: 934948.6250 - val_mae: 960.2899\n",
      "Epoch 24/200\n",
      "91/98 [==========================>...] - ETA: 0s - loss: 902589.6250 - mae: 943.6000\n",
      "Epoch 24: val_loss improved from 934948.62500 to 912832.56250, saving model to ./\n",
      "INFO:tensorflow:Assets written to: ./assets\n",
      "98/98 [==============================] - 2s 16ms/step - loss: 902245.4375 - mae: 943.3542 - val_loss: 912832.5625 - val_mae: 947.8613\n",
      "Epoch 25/200\n",
      "88/98 [=========================>....] - ETA: 0s - loss: 879257.9375 - mae: 930.2996\n",
      "Epoch 25: val_loss improved from 912832.56250 to 890943.00000, saving model to ./\n",
      "INFO:tensorflow:Assets written to: ./assets\n",
      "98/98 [==============================] - 2s 16ms/step - loss: 878730.8750 - mae: 930.1347 - val_loss: 890943.0000 - val_mae: 935.2701\n",
      "Epoch 26/200\n",
      "89/98 [==========================>...] - ETA: 0s - loss: 853607.5625 - mae: 915.9333\n",
      "Epoch 26: val_loss improved from 890943.00000 to 869164.25000, saving model to ./\n",
      "INFO:tensorflow:Assets written to: ./assets\n",
      "98/98 [==============================] - 2s 16ms/step - loss: 855244.1250 - mae: 916.6758 - val_loss: 869164.2500 - val_mae: 922.3890\n",
      "Epoch 27/200\n",
      "88/98 [=========================>....] - ETA: 0s - loss: 830033.3750 - mae: 901.9769\n",
      "Epoch 27: val_loss improved from 869164.25000 to 847730.56250, saving model to ./\n",
      "INFO:tensorflow:Assets written to: ./assets\n",
      "98/98 [==============================] - 2s 16ms/step - loss: 831854.3125 - mae: 903.0545 - val_loss: 847730.5625 - val_mae: 909.3945\n",
      "Epoch 28/200\n",
      "88/98 [=========================>....] - ETA: 0s - loss: 810137.8125 - mae: 890.1435\n",
      "Epoch 28: val_loss improved from 847730.56250 to 826615.06250, saving model to ./\n",
      "INFO:tensorflow:Assets written to: ./assets\n",
      "98/98 [==============================] - 2s 17ms/step - loss: 808582.1875 - mae: 889.2354 - val_loss: 826615.0625 - val_mae: 896.2098\n",
      "Epoch 29/200\n",
      "86/98 [=========================>....] - ETA: 0s - loss: 788460.1875 - mae: 877.1931\n",
      "Epoch 29: val_loss improved from 826615.06250 to 805735.37500, saving model to ./\n",
      "INFO:tensorflow:Assets written to: ./assets\n",
      "98/98 [==============================] - 2s 16ms/step - loss: 785434.1875 - mae: 875.2079 - val_loss: 805735.3750 - val_mae: 882.7914\n",
      "Epoch 30/200\n",
      "81/98 [=======================>......] - ETA: 0s - loss: 764211.8750 - mae: 862.2241\n",
      "Epoch 30: val_loss improved from 805735.37500 to 785411.43750, saving model to ./\n",
      "INFO:tensorflow:Assets written to: ./assets\n",
      "98/98 [==============================] - 2s 22ms/step - loss: 762487.6250 - mae: 861.0607 - val_loss: 785411.4375 - val_mae: 869.2849\n",
      "Epoch 31/200\n",
      "89/98 [==========================>...] - ETA: 0s - loss: 741230.6250 - mae: 847.5417\n",
      "Epoch 31: val_loss improved from 785411.43750 to 765515.18750, saving model to ./\n",
      "INFO:tensorflow:Assets written to: ./assets\n",
      "98/98 [==============================] - 2s 16ms/step - loss: 739851.7500 - mae: 846.8519 - val_loss: 765515.1875 - val_mae: 855.6678\n",
      "Epoch 32/200\n",
      "87/98 [=========================>....] - ETA: 0s - loss: 719866.0000 - mae: 833.9586\n",
      "Epoch 32: val_loss improved from 765515.18750 to 746115.62500, saving model to ./\n",
      "INFO:tensorflow:Assets written to: ./assets\n",
      "98/98 [==============================] - 2s 16ms/step - loss: 717476.3125 - mae: 832.4998 - val_loss: 746115.6250 - val_mae: 841.9207\n",
      "Epoch 33/200\n",
      "90/98 [==========================>...] - ETA: 0s - loss: 697991.5625 - mae: 819.6400\n",
      "Epoch 33: val_loss improved from 746115.62500 to 727173.50000, saving model to ./\n",
      "INFO:tensorflow:Assets written to: ./assets\n",
      "98/98 [==============================] - 2s 16ms/step - loss: 695441.9375 - mae: 818.1343 - val_loss: 727173.5000 - val_mae: 828.0583\n",
      "Epoch 34/200\n",
      "91/98 [==========================>...] - ETA: 0s - loss: 676433.1250 - mae: 805.1318\n",
      "Epoch 34: val_loss improved from 727173.50000 to 708882.25000, saving model to ./\n",
      "INFO:tensorflow:Assets written to: ./assets\n",
      "98/98 [==============================] - 2s 16ms/step - loss: 673737.4375 - mae: 803.6958 - val_loss: 708882.2500 - val_mae: 814.1324\n",
      "Epoch 35/200\n",
      "83/98 [========================>.....] - ETA: 0s - loss: 658191.4375 - mae: 792.8290\n",
      "Epoch 35: val_loss improved from 708882.25000 to 691054.25000, saving model to ./\n",
      "INFO:tensorflow:Assets written to: ./assets\n",
      "98/98 [==============================] - 2s 21ms/step - loss: 652402.3750 - mae: 789.0626 - val_loss: 691054.2500 - val_mae: 800.0795\n",
      "Epoch 36/200\n",
      "91/98 [==========================>...] - ETA: 0s - loss: 634148.5625 - mae: 776.3079\n",
      "Epoch 36: val_loss improved from 691054.25000 to 673815.37500, saving model to ./\n",
      "INFO:tensorflow:Assets written to: ./assets\n",
      "98/98 [==============================] - 2s 16ms/step - loss: 631506.5000 - mae: 774.4619 - val_loss: 673815.3750 - val_mae: 786.0586\n",
      "Epoch 37/200\n",
      "86/98 [=========================>....] - ETA: 0s - loss: 612543.0625 - mae: 760.6703\n",
      "Epoch 37: val_loss improved from 673815.37500 to 657186.00000, saving model to ./\n",
      "INFO:tensorflow:Assets written to: ./assets\n",
      "98/98 [==============================] - 2s 16ms/step - loss: 610948.1875 - mae: 759.8763 - val_loss: 657186.0000 - val_mae: 772.1932\n",
      "Epoch 38/200\n",
      "85/98 [=========================>....] - ETA: 0s - loss: 592293.5625 - mae: 745.9206\n",
      "Epoch 38: val_loss improved from 657186.00000 to 641156.12500, saving model to ./\n",
      "INFO:tensorflow:Assets written to: ./assets\n",
      "98/98 [==============================] - 2s 16ms/step - loss: 590881.5625 - mae: 745.0003 - val_loss: 641156.1250 - val_mae: 758.1944\n",
      "Epoch 39/200\n",
      "89/98 [==========================>...] - ETA: 0s - loss: 569422.5000 - mae: 728.8718\n",
      "Epoch 39: val_loss improved from 641156.12500 to 625796.81250, saving model to ./\n",
      "INFO:tensorflow:Assets written to: ./assets\n",
      "98/98 [==============================] - 2s 16ms/step - loss: 571212.5625 - mae: 730.2933 - val_loss: 625796.8125 - val_mae: 744.2166\n",
      "Epoch 40/200\n",
      "91/98 [==========================>...] - ETA: 0s - loss: 551589.4375 - mae: 715.1999\n",
      "Epoch 40: val_loss improved from 625796.81250 to 611068.62500, saving model to ./\n",
      "INFO:tensorflow:Assets written to: ./assets\n",
      "98/98 [==============================] - 2s 16ms/step - loss: 552010.5625 - mae: 715.6554 - val_loss: 611068.6250 - val_mae: 730.2172\n",
      "Epoch 41/200\n",
      "88/98 [=========================>....] - ETA: 0s - loss: 536963.4375 - mae: 702.8264\n",
      "Epoch 41: val_loss improved from 611068.62500 to 596993.87500, saving model to ./\n",
      "INFO:tensorflow:Assets written to: ./assets\n",
      "98/98 [==============================] - 2s 22ms/step - loss: 533283.5000 - mae: 700.7868 - val_loss: 596993.8750 - val_mae: 716.2001\n",
      "Epoch 42/200\n",
      "90/98 [==========================>...] - ETA: 0s - loss: 517671.3750 - mae: 688.1215\n",
      "Epoch 42: val_loss improved from 596993.87500 to 583392.43750, saving model to ./\n",
      "INFO:tensorflow:Assets written to: ./assets\n",
      "98/98 [==============================] - 2s 16ms/step - loss: 515073.3438 - mae: 686.0941 - val_loss: 583392.4375 - val_mae: 702.1468\n",
      "Epoch 43/200\n",
      "92/98 [===========================>..] - ETA: 0s - loss: 497935.5625 - mae: 671.7240\n",
      "Epoch 43: val_loss improved from 583392.43750 to 570458.31250, saving model to ./\n",
      "INFO:tensorflow:Assets written to: ./assets\n",
      "98/98 [==============================] - 2s 17ms/step - loss: 497387.8438 - mae: 671.5251 - val_loss: 570458.3125 - val_mae: 688.1900\n",
      "Epoch 44/200\n",
      "90/98 [==========================>...] - ETA: 0s - loss: 482946.3438 - mae: 658.8185\n",
      "Epoch 44: val_loss improved from 570458.31250 to 558117.50000, saving model to ./\n",
      "INFO:tensorflow:Assets written to: ./assets\n",
      "98/98 [==============================] - 2s 16ms/step - loss: 480188.7188 - mae: 657.0198 - val_loss: 558117.5000 - val_mae: 674.4519\n",
      "Epoch 45/200\n",
      "83/98 [========================>.....] - ETA: 0s - loss: 465620.1875 - mae: 643.2084\n",
      "Epoch 45: val_loss improved from 558117.50000 to 546437.00000, saving model to ./\n",
      "INFO:tensorflow:Assets written to: ./assets\n",
      "98/98 [==============================] - 2s 16ms/step - loss: 463515.8750 - mae: 642.7401 - val_loss: 546437.0000 - val_mae: 661.1364\n",
      "Epoch 46/200\n",
      "90/98 [==========================>...] - ETA: 0s - loss: 447324.5312 - mae: 628.0820\n",
      "Epoch 46: val_loss improved from 546437.00000 to 535204.68750, saving model to ./\n",
      "INFO:tensorflow:Assets written to: ./assets\n",
      "98/98 [==============================] - 2s 16ms/step - loss: 447315.0625 - mae: 628.3378 - val_loss: 535204.6875 - val_mae: 647.9972\n",
      "Epoch 47/200\n",
      "90/98 [==========================>...] - ETA: 0s - loss: 433196.3438 - mae: 615.2297\n",
      "Epoch 47: val_loss improved from 535204.68750 to 524519.06250, saving model to ./\n",
      "INFO:tensorflow:Assets written to: ./assets\n",
      "98/98 [==============================] - 2s 22ms/step - loss: 431632.1875 - mae: 614.2274 - val_loss: 524519.0625 - val_mae: 635.0146\n",
      "Epoch 48/200\n",
      "87/98 [=========================>....] - ETA: 0s - loss: 417682.6562 - mae: 600.4634\n",
      "Epoch 48: val_loss improved from 524519.06250 to 514310.62500, saving model to ./\n",
      "INFO:tensorflow:Assets written to: ./assets\n",
      "98/98 [==============================] - 2s 16ms/step - loss: 416480.1562 - mae: 600.1340 - val_loss: 514310.6250 - val_mae: 622.2211\n",
      "Epoch 49/200\n",
      "86/98 [=========================>....] - ETA: 0s - loss: 400087.2188 - mae: 585.2838\n",
      "Epoch 49: val_loss improved from 514310.62500 to 504709.15625, saving model to ./\n",
      "INFO:tensorflow:Assets written to: ./assets\n",
      "98/98 [==============================] - 2s 18ms/step - loss: 401810.1562 - mae: 586.6818 - val_loss: 504709.1562 - val_mae: 609.9886\n",
      "Epoch 50/200\n",
      "88/98 [=========================>....] - ETA: 0s - loss: 389180.1875 - mae: 574.4155\n",
      "Epoch 50: val_loss improved from 504709.15625 to 495344.40625, saving model to ./\n",
      "INFO:tensorflow:Assets written to: ./assets\n",
      "98/98 [==============================] - 2s 16ms/step - loss: 387645.4375 - mae: 573.0179 - val_loss: 495344.4062 - val_mae: 597.8898\n",
      "Epoch 51/200\n",
      "88/98 [=========================>....] - ETA: 0s - loss: 373069.1562 - mae: 558.6399\n",
      "Epoch 51: val_loss improved from 495344.40625 to 486630.87500, saving model to ./\n",
      "INFO:tensorflow:Assets written to: ./assets\n",
      "98/98 [==============================] - 2s 17ms/step - loss: 373979.5000 - mae: 559.6862 - val_loss: 486630.8750 - val_mae: 585.8169\n",
      "Epoch 52/200\n",
      "89/98 [==========================>...] - ETA: 0s - loss: 363035.4062 - mae: 547.0493\n",
      "Epoch 52: val_loss improved from 486630.87500 to 477880.31250, saving model to ./\n",
      "INFO:tensorflow:Assets written to: ./assets\n",
      "98/98 [==============================] - 2s 16ms/step - loss: 360795.2500 - mae: 546.5703 - val_loss: 477880.3125 - val_mae: 574.2057\n",
      "Epoch 53/200\n",
      "87/98 [=========================>....] - ETA: 0s - loss: 353428.9688 - mae: 538.2971\n",
      "Epoch 53: val_loss improved from 477880.31250 to 469648.09375, saving model to ./\n",
      "INFO:tensorflow:Assets written to: ./assets\n",
      "98/98 [==============================] - 2s 22ms/step - loss: 348050.5625 - mae: 533.5556 - val_loss: 469648.0938 - val_mae: 562.6629\n",
      "Epoch 54/200\n",
      "88/98 [=========================>....] - ETA: 0s - loss: 338594.9688 - mae: 523.0286\n",
      "Epoch 54: val_loss improved from 469648.09375 to 461702.75000, saving model to ./\n",
      "INFO:tensorflow:Assets written to: ./assets\n",
      "98/98 [==============================] - 2s 17ms/step - loss: 335725.2188 - mae: 521.1423 - val_loss: 461702.7500 - val_mae: 551.5760\n",
      "Epoch 55/200\n",
      "89/98 [==========================>...] - ETA: 0s - loss: 317257.3125 - mae: 508.4117\n",
      "Epoch 55: val_loss improved from 461702.75000 to 453774.21875, saving model to ./\n",
      "INFO:tensorflow:Assets written to: ./assets\n",
      "98/98 [==============================] - 2s 17ms/step - loss: 323898.3438 - mae: 508.8636 - val_loss: 453774.2188 - val_mae: 540.2278\n",
      "Epoch 56/200\n",
      "90/98 [==========================>...] - ETA: 0s - loss: 314988.5625 - mae: 499.3181\n",
      "Epoch 56: val_loss improved from 453774.21875 to 446650.56250, saving model to ./\n",
      "INFO:tensorflow:Assets written to: ./assets\n",
      "98/98 [==============================] - 2s 17ms/step - loss: 312395.2500 - mae: 497.1558 - val_loss: 446650.5625 - val_mae: 529.5986\n",
      "Epoch 57/200\n",
      "91/98 [==========================>...] - ETA: 0s - loss: 304437.8438 - mae: 488.5137\n",
      "Epoch 57: val_loss improved from 446650.56250 to 439430.62500, saving model to ./\n",
      "INFO:tensorflow:Assets written to: ./assets\n",
      "98/98 [==============================] - 2s 17ms/step - loss: 301383.4375 - mae: 485.7220 - val_loss: 439430.6250 - val_mae: 519.0726\n",
      "Epoch 58/200\n",
      "89/98 [==========================>...] - ETA: 0s - loss: 293415.9375 - mae: 475.9757\n",
      "Epoch 58: val_loss improved from 439430.62500 to 432862.03125, saving model to ./\n",
      "INFO:tensorflow:Assets written to: ./assets\n",
      "98/98 [==============================] - 2s 17ms/step - loss: 290716.9375 - mae: 474.5706 - val_loss: 432862.0312 - val_mae: 508.9627\n",
      "Epoch 59/200\n",
      "90/98 [==========================>...] - ETA: 0s - loss: 282925.1250 - mae: 465.0456\n",
      "Epoch 59: val_loss improved from 432862.03125 to 426266.50000, saving model to ./\n",
      "INFO:tensorflow:Assets written to: ./assets\n",
      "98/98 [==============================] - 2s 21ms/step - loss: 280476.4375 - mae: 463.6141 - val_loss: 426266.5000 - val_mae: 499.1602\n",
      "Epoch 60/200\n",
      "92/98 [===========================>..] - ETA: 0s - loss: 271350.6250 - mae: 453.1963\n",
      "Epoch 60: val_loss improved from 426266.50000 to 419608.15625, saving model to ./\n",
      "INFO:tensorflow:Assets written to: ./assets\n",
      "98/98 [==============================] - 2s 16ms/step - loss: 270506.7188 - mae: 452.9118 - val_loss: 419608.1562 - val_mae: 489.5789\n",
      "Epoch 61/200\n",
      "86/98 [=========================>....] - ETA: 0s - loss: 253988.2812 - mae: 443.1238\n",
      "Epoch 61: val_loss improved from 419608.15625 to 413265.46875, saving model to ./\n",
      "INFO:tensorflow:Assets written to: ./assets\n",
      "98/98 [==============================] - 2s 17ms/step - loss: 260883.4219 - mae: 442.2669 - val_loss: 413265.4688 - val_mae: 480.0936\n",
      "Epoch 62/200\n",
      "88/98 [=========================>....] - ETA: 0s - loss: 253416.2656 - mae: 432.9317\n",
      "Epoch 62: val_loss improved from 413265.46875 to 407216.00000, saving model to ./\n",
      "INFO:tensorflow:Assets written to: ./assets\n",
      "98/98 [==============================] - 2s 17ms/step - loss: 251510.9219 - mae: 432.3776 - val_loss: 407216.0000 - val_mae: 470.8899\n",
      "Epoch 63/200\n",
      "88/98 [=========================>....] - ETA: 0s - loss: 243764.7344 - mae: 423.0311\n",
      "Epoch 63: val_loss improved from 407216.00000 to 401274.31250, saving model to ./\n",
      "INFO:tensorflow:Assets written to: ./assets\n",
      "98/98 [==============================] - 2s 17ms/step - loss: 242546.5000 - mae: 422.5222 - val_loss: 401274.3125 - val_mae: 461.6242\n",
      "Epoch 64/200\n",
      "90/98 [==========================>...] - ETA: 0s - loss: 234892.2656 - mae: 412.4879\n",
      "Epoch 64: val_loss improved from 401274.31250 to 395316.71875, saving model to ./\n",
      "INFO:tensorflow:Assets written to: ./assets\n",
      "98/98 [==============================] - 2s 16ms/step - loss: 233855.5469 - mae: 412.6545 - val_loss: 395316.7188 - val_mae: 452.6996\n",
      "Epoch 65/200\n",
      "91/98 [==========================>...] - ETA: 0s - loss: 227482.0938 - mae: 404.9238\n",
      "Epoch 65: val_loss improved from 395316.71875 to 389438.68750, saving model to ./\n",
      "INFO:tensorflow:Assets written to: ./assets\n",
      "98/98 [==============================] - 2s 21ms/step - loss: 225444.3906 - mae: 403.0699 - val_loss: 389438.6875 - val_mae: 443.7206\n",
      "Epoch 66/200\n",
      "92/98 [===========================>..] - ETA: 0s - loss: 217202.7969 - mae: 393.6883\n",
      "Epoch 66: val_loss improved from 389438.68750 to 383369.65625, saving model to ./\n",
      "INFO:tensorflow:Assets written to: ./assets\n",
      "98/98 [==============================] - 2s 16ms/step - loss: 217297.5312 - mae: 393.9799 - val_loss: 383369.6562 - val_mae: 435.1091\n",
      "Epoch 67/200\n",
      "88/98 [=========================>....] - ETA: 0s - loss: 208445.4844 - mae: 382.6059\n",
      "Epoch 67: val_loss improved from 383369.65625 to 377957.25000, saving model to ./\n",
      "INFO:tensorflow:Assets written to: ./assets\n",
      "98/98 [==============================] - 2s 17ms/step - loss: 209458.9375 - mae: 385.0508 - val_loss: 377957.2500 - val_mae: 426.6596\n",
      "Epoch 68/200\n",
      "80/98 [=======================>......] - ETA: 0s - loss: 204371.8125 - mae: 378.2864\n",
      "Epoch 68: val_loss improved from 377957.25000 to 372354.37500, saving model to ./\n",
      "INFO:tensorflow:Assets written to: ./assets\n",
      "98/98 [==============================] - 2s 16ms/step - loss: 201889.4844 - mae: 376.2578 - val_loss: 372354.3750 - val_mae: 418.2078\n",
      "Epoch 69/200\n",
      "86/98 [=========================>....] - ETA: 0s - loss: 195878.2812 - mae: 367.7526\n",
      "Epoch 69: val_loss improved from 372354.37500 to 366769.15625, saving model to ./\n",
      "INFO:tensorflow:Assets written to: ./assets\n",
      "98/98 [==============================] - 2s 17ms/step - loss: 194564.7500 - mae: 367.8647 - val_loss: 366769.1562 - val_mae: 409.9112\n",
      "Epoch 70/200\n",
      "93/98 [===========================>..] - ETA: 0s - loss: 189535.8438 - mae: 360.7317\n",
      "Epoch 70: val_loss improved from 366769.15625 to 361239.78125, saving model to ./\n",
      "INFO:tensorflow:Assets written to: ./assets\n",
      "98/98 [==============================] - 2s 17ms/step - loss: 187454.7500 - mae: 359.2063 - val_loss: 361239.7812 - val_mae: 401.4441\n",
      "Epoch 71/200\n",
      "89/98 [==========================>...] - ETA: 0s - loss: 182757.8125 - mae: 352.6229\n",
      "Epoch 71: val_loss improved from 361239.78125 to 355687.93750, saving model to ./\n",
      "INFO:tensorflow:Assets written to: ./assets\n",
      "98/98 [==============================] - 2s 21ms/step - loss: 180527.1250 - mae: 350.8179 - val_loss: 355687.9375 - val_mae: 393.1747\n",
      "Epoch 72/200\n",
      "91/98 [==========================>...] - ETA: 0s - loss: 174418.4688 - mae: 341.8037\n",
      "Epoch 72: val_loss improved from 355687.93750 to 350506.12500, saving model to ./\n",
      "INFO:tensorflow:Assets written to: ./assets\n",
      "98/98 [==============================] - 2s 16ms/step - loss: 173777.0781 - mae: 342.4108 - val_loss: 350506.1250 - val_mae: 385.0488\n",
      "Epoch 73/200\n",
      "86/98 [=========================>....] - ETA: 0s - loss: 170172.5156 - mae: 334.9353\n",
      "Epoch 73: val_loss improved from 350506.12500 to 344780.21875, saving model to ./\n",
      "INFO:tensorflow:Assets written to: ./assets\n",
      "98/98 [==============================] - 2s 17ms/step - loss: 167245.9375 - mae: 334.2128 - val_loss: 344780.2188 - val_mae: 376.7967\n",
      "Epoch 74/200\n",
      "91/98 [==========================>...] - ETA: 0s - loss: 162647.9375 - mae: 326.6353\n",
      "Epoch 74: val_loss improved from 344780.21875 to 339489.28125, saving model to ./\n",
      "INFO:tensorflow:Assets written to: ./assets\n",
      "98/98 [==============================] - 2s 17ms/step - loss: 160946.5312 - mae: 326.2770 - val_loss: 339489.2812 - val_mae: 368.7029\n",
      "Epoch 75/200\n",
      "92/98 [===========================>..] - ETA: 0s - loss: 156605.7500 - mae: 319.2878\n",
      "Epoch 75: val_loss improved from 339489.28125 to 334287.46875, saving model to ./\n",
      "INFO:tensorflow:Assets written to: ./assets\n",
      "98/98 [==============================] - 2s 17ms/step - loss: 154823.2500 - mae: 318.2341 - val_loss: 334287.4688 - val_mae: 360.6807\n",
      "Epoch 76/200\n",
      "86/98 [=========================>....] - ETA: 0s - loss: 151800.2344 - mae: 311.6570\n",
      "Epoch 76: val_loss improved from 334287.46875 to 329046.40625, saving model to ./\n",
      "INFO:tensorflow:Assets written to: ./assets\n",
      "98/98 [==============================] - 2s 16ms/step - loss: 148964.6562 - mae: 310.4788 - val_loss: 329046.4062 - val_mae: 352.7601\n",
      "Epoch 77/200\n",
      "91/98 [==========================>...] - ETA: 0s - loss: 144235.7188 - mae: 303.4535\n",
      "Epoch 77: val_loss improved from 329046.40625 to 323985.96875, saving model to ./\n",
      "INFO:tensorflow:Assets written to: ./assets\n",
      "98/98 [==============================] - 2s 16ms/step - loss: 143271.0312 - mae: 302.8777 - val_loss: 323985.9688 - val_mae: 345.1120\n",
      "Epoch 78/200\n",
      "90/98 [==========================>...] - ETA: 0s - loss: 136538.7500 - mae: 293.0005\n",
      "Epoch 78: val_loss improved from 323985.96875 to 318941.18750, saving model to ./\n",
      "INFO:tensorflow:Assets written to: ./assets\n",
      "98/98 [==============================] - 2s 22ms/step - loss: 137779.7500 - mae: 295.2052 - val_loss: 318941.1875 - val_mae: 337.5255\n",
      "Epoch 79/200\n",
      "91/98 [==========================>...] - ETA: 0s - loss: 133825.8594 - mae: 287.5662\n",
      "Epoch 79: val_loss improved from 318941.18750 to 313738.43750, saving model to ./\n",
      "INFO:tensorflow:Assets written to: ./assets\n",
      "98/98 [==============================] - 2s 17ms/step - loss: 132496.7188 - mae: 287.6732 - val_loss: 313738.4375 - val_mae: 330.0273\n",
      "Epoch 80/200\n",
      "89/98 [==========================>...] - ETA: 0s - loss: 116998.7500 - mae: 277.5568\n",
      "Epoch 80: val_loss improved from 313738.43750 to 308345.25000, saving model to ./\n",
      "INFO:tensorflow:Assets written to: ./assets\n",
      "98/98 [==============================] - 2s 17ms/step - loss: 127381.4844 - mae: 280.3998 - val_loss: 308345.2500 - val_mae: 322.4757\n",
      "Epoch 81/200\n",
      "85/98 [=========================>....] - ETA: 0s - loss: 108562.1875 - mae: 271.6451\n",
      "Epoch 81: val_loss improved from 308345.25000 to 303762.81250, saving model to ./\n",
      "INFO:tensorflow:Assets written to: ./assets\n",
      "98/98 [==============================] - 2s 16ms/step - loss: 122367.7812 - mae: 273.1724 - val_loss: 303762.8125 - val_mae: 315.2849\n",
      "Epoch 82/200\n",
      "90/98 [==========================>...] - ETA: 0s - loss: 119875.3203 - mae: 267.2838\n",
      "Epoch 82: val_loss improved from 303762.81250 to 298410.09375, saving model to ./\n",
      "INFO:tensorflow:Assets written to: ./assets\n",
      "98/98 [==============================] - 2s 16ms/step - loss: 117557.0234 - mae: 266.1310 - val_loss: 298410.0938 - val_mae: 308.1094\n",
      "Epoch 83/200\n",
      "88/98 [=========================>....] - ETA: 0s - loss: 106386.6016 - mae: 254.2055\n",
      "Epoch 83: val_loss improved from 298410.09375 to 294013.87500, saving model to ./\n",
      "INFO:tensorflow:Assets written to: ./assets\n",
      "98/98 [==============================] - 2s 17ms/step - loss: 112886.8594 - mae: 259.0576 - val_loss: 294013.8750 - val_mae: 300.9116\n",
      "Epoch 84/200\n",
      "92/98 [===========================>..] - ETA: 0s - loss: 109548.9922 - mae: 253.2001\n",
      "Epoch 84: val_loss improved from 294013.87500 to 288247.71875, saving model to ./\n",
      "INFO:tensorflow:Assets written to: ./assets\n",
      "98/98 [==============================] - 2s 21ms/step - loss: 108419.6719 - mae: 252.4551 - val_loss: 288247.7188 - val_mae: 293.8369\n",
      "Epoch 85/200\n",
      "88/98 [=========================>....] - ETA: 0s - loss: 106448.7188 - mae: 246.4664\n",
      "Epoch 85: val_loss improved from 288247.71875 to 283331.65625, saving model to ./\n",
      "INFO:tensorflow:Assets written to: ./assets\n",
      "98/98 [==============================] - 2s 17ms/step - loss: 104090.3281 - mae: 245.5679 - val_loss: 283331.6562 - val_mae: 286.8080\n",
      "Epoch 86/200\n",
      "78/98 [======================>.......] - ETA: 0s - loss: 96820.0938 - mae: 234.4959 \n",
      "Epoch 86: val_loss improved from 283331.65625 to 278930.31250, saving model to ./\n",
      "INFO:tensorflow:Assets written to: ./assets\n",
      "98/98 [==============================] - 2s 17ms/step - loss: 99942.4375 - mae: 238.8681 - val_loss: 278930.3125 - val_mae: 279.8803\n",
      "Epoch 87/200\n",
      "91/98 [==========================>...] - ETA: 0s - loss: 96725.1406 - mae: 231.9598\n",
      "Epoch 87: val_loss improved from 278930.31250 to 273774.71875, saving model to ./\n",
      "INFO:tensorflow:Assets written to: ./assets\n",
      "98/98 [==============================] - 2s 16ms/step - loss: 95958.8047 - mae: 232.1475 - val_loss: 273774.7188 - val_mae: 272.9217\n",
      "Epoch 88/200\n",
      "88/98 [=========================>....] - ETA: 0s - loss: 95786.7422 - mae: 228.6153\n",
      "Epoch 88: val_loss improved from 273774.71875 to 268714.18750, saving model to ./\n",
      "INFO:tensorflow:Assets written to: ./assets\n",
      "98/98 [==============================] - 2s 16ms/step - loss: 92100.3281 - mae: 225.8264 - val_loss: 268714.1875 - val_mae: 266.1786\n",
      "Epoch 89/200\n",
      "91/98 [==========================>...] - ETA: 0s - loss: 89803.8125 - mae: 219.2955\n",
      "Epoch 89: val_loss improved from 268714.18750 to 264006.75000, saving model to ./\n",
      "INFO:tensorflow:Assets written to: ./assets\n",
      "98/98 [==============================] - 2s 21ms/step - loss: 88349.0469 - mae: 219.0383 - val_loss: 264006.7500 - val_mae: 259.2820\n",
      "Epoch 90/200\n",
      "87/98 [=========================>....] - ETA: 0s - loss: 87557.1406 - mae: 213.9170\n",
      "Epoch 90: val_loss improved from 264006.75000 to 259255.07812, saving model to ./\n",
      "INFO:tensorflow:Assets written to: ./assets\n",
      "98/98 [==============================] - 2s 16ms/step - loss: 84747.2031 - mae: 212.8435 - val_loss: 259255.0781 - val_mae: 252.5914\n",
      "Epoch 91/200\n",
      "90/98 [==========================>...] - ETA: 0s - loss: 82366.4766 - mae: 207.7253\n",
      "Epoch 91: val_loss improved from 259255.07812 to 254447.32812, saving model to ./\n",
      "INFO:tensorflow:Assets written to: ./assets\n",
      "98/98 [==============================] - 2s 16ms/step - loss: 81271.5391 - mae: 206.4498 - val_loss: 254447.3281 - val_mae: 245.9343\n",
      "Epoch 92/200\n",
      "88/98 [=========================>....] - ETA: 0s - loss: 76425.8516 - mae: 199.3008\n",
      "Epoch 92: val_loss improved from 254447.32812 to 249948.28125, saving model to ./\n",
      "INFO:tensorflow:Assets written to: ./assets\n",
      "98/98 [==============================] - 2s 17ms/step - loss: 77930.1875 - mae: 200.3311 - val_loss: 249948.2812 - val_mae: 239.3649\n",
      "Epoch 93/200\n",
      "90/98 [==========================>...] - ETA: 0s - loss: 70700.7969 - mae: 192.5431\n",
      "Epoch 93: val_loss improved from 249948.28125 to 245743.23438, saving model to ./\n",
      "INFO:tensorflow:Assets written to: ./assets\n",
      "98/98 [==============================] - 2s 16ms/step - loss: 74707.8672 - mae: 194.0952 - val_loss: 245743.2344 - val_mae: 232.8934\n",
      "Epoch 94/200\n",
      "87/98 [=========================>....] - ETA: 0s - loss: 62341.6211 - mae: 185.9676\n",
      "Epoch 94: val_loss improved from 245743.23438 to 240535.56250, saving model to ./\n",
      "INFO:tensorflow:Assets written to: ./assets\n",
      "98/98 [==============================] - 2s 16ms/step - loss: 71625.3906 - mae: 188.0401 - val_loss: 240535.5625 - val_mae: 226.5434\n",
      "Epoch 95/200\n",
      "88/98 [=========================>....] - ETA: 0s - loss: 71219.3125 - mae: 184.0748\n",
      "Epoch 95: val_loss improved from 240535.56250 to 235968.89062, saving model to ./\n",
      "INFO:tensorflow:Assets written to: ./assets\n",
      "98/98 [==============================] - 2s 16ms/step - loss: 68708.3359 - mae: 182.2464 - val_loss: 235968.8906 - val_mae: 220.3262\n",
      "Epoch 96/200\n",
      "92/98 [===========================>..] - ETA: 0s - loss: 64851.5156 - mae: 174.7369\n",
      "Epoch 96: val_loss improved from 235968.89062 to 231646.81250, saving model to ./\n",
      "INFO:tensorflow:Assets written to: ./assets\n",
      "98/98 [==============================] - 2s 22ms/step - loss: 65905.9141 - mae: 176.4782 - val_loss: 231646.8125 - val_mae: 214.0682\n",
      "Epoch 97/200\n",
      "93/98 [===========================>..] - ETA: 0s - loss: 63593.1016 - mae: 170.2829\n",
      "Epoch 97: val_loss improved from 231646.81250 to 227854.15625, saving model to ./\n",
      "INFO:tensorflow:Assets written to: ./assets\n",
      "98/98 [==============================] - 2s 17ms/step - loss: 63220.6680 - mae: 170.8791 - val_loss: 227854.1562 - val_mae: 208.0084\n",
      "Epoch 98/200\n",
      "87/98 [=========================>....] - ETA: 0s - loss: 63749.1836 - mae: 167.1954\n",
      "Epoch 98: val_loss improved from 227854.15625 to 222966.12500, saving model to ./\n",
      "INFO:tensorflow:Assets written to: ./assets\n",
      "98/98 [==============================] - 2s 17ms/step - loss: 60691.4766 - mae: 165.4020 - val_loss: 222966.1250 - val_mae: 201.9654\n",
      "Epoch 99/200\n",
      "89/98 [==========================>...] - ETA: 0s - loss: 60963.6914 - mae: 162.6566\n",
      "Epoch 99: val_loss improved from 222966.12500 to 219008.64062, saving model to ./\n",
      "INFO:tensorflow:Assets written to: ./assets\n",
      "98/98 [==============================] - 2s 16ms/step - loss: 58247.4453 - mae: 160.0071 - val_loss: 219008.6406 - val_mae: 196.0312\n",
      "Epoch 100/200\n",
      "90/98 [==========================>...] - ETA: 0s - loss: 58686.7852 - mae: 157.5074\n",
      "Epoch 100: val_loss improved from 219008.64062 to 214515.82812, saving model to ./\n",
      "INFO:tensorflow:Assets written to: ./assets\n",
      "98/98 [==============================] - 2s 16ms/step - loss: 55917.8281 - mae: 154.6376 - val_loss: 214515.8281 - val_mae: 190.1197\n",
      "Epoch 101/200\n",
      "91/98 [==========================>...] - ETA: 0s - loss: 54865.9336 - mae: 148.9576\n",
      "Epoch 101: val_loss improved from 214515.82812 to 210615.14062, saving model to ./\n",
      "INFO:tensorflow:Assets written to: ./assets\n",
      "98/98 [==============================] - 2s 21ms/step - loss: 53690.1406 - mae: 149.3012 - val_loss: 210615.1406 - val_mae: 184.6034\n",
      "Epoch 102/200\n",
      "86/98 [=========================>....] - ETA: 0s - loss: 54951.8789 - mae: 146.5771\n",
      "Epoch 102: val_loss improved from 210615.14062 to 206289.25000, saving model to ./\n",
      "INFO:tensorflow:Assets written to: ./assets\n",
      "98/98 [==============================] - 2s 16ms/step - loss: 51567.1289 - mae: 144.3941 - val_loss: 206289.2500 - val_mae: 178.9094\n",
      "Epoch 103/200\n",
      "89/98 [==========================>...] - ETA: 0s - loss: 40906.1836 - mae: 138.0654\n",
      "Epoch 103: val_loss improved from 206289.25000 to 202301.78125, saving model to ./\n",
      "INFO:tensorflow:Assets written to: ./assets\n",
      "98/98 [==============================] - 2s 16ms/step - loss: 49548.0859 - mae: 139.1666 - val_loss: 202301.7812 - val_mae: 173.1842\n",
      "Epoch 104/200\n",
      "89/98 [==========================>...] - ETA: 0s - loss: 39007.3594 - mae: 132.2918\n",
      "Epoch 104: val_loss improved from 202301.78125 to 198692.03125, saving model to ./\n",
      "INFO:tensorflow:Assets written to: ./assets\n",
      "98/98 [==============================] - 2s 16ms/step - loss: 47565.6445 - mae: 134.1686 - val_loss: 198692.0312 - val_mae: 167.9689\n",
      "Epoch 105/200\n",
      "85/98 [=========================>....] - ETA: 0s - loss: 32563.9883 - mae: 126.8103\n",
      "Epoch 105: val_loss improved from 198692.03125 to 195333.76562, saving model to ./\n",
      "INFO:tensorflow:Assets written to: ./assets\n",
      "98/98 [==============================] - 2s 17ms/step - loss: 45746.2773 - mae: 129.3588 - val_loss: 195333.7656 - val_mae: 162.7045\n",
      "Epoch 106/200\n",
      "80/98 [=======================>......] - ETA: 0s - loss: 41211.6953 - mae: 124.0286\n",
      "Epoch 106: val_loss improved from 195333.76562 to 191620.64062, saving model to ./\n",
      "INFO:tensorflow:Assets written to: ./assets\n",
      "98/98 [==============================] - 2s 17ms/step - loss: 43962.4531 - mae: 124.7367 - val_loss: 191620.6406 - val_mae: 157.7189\n",
      "Epoch 107/200\n",
      "87/98 [=========================>....] - ETA: 0s - loss: 45100.8672 - mae: 122.2030\n",
      "Epoch 107: val_loss improved from 191620.64062 to 186922.87500, saving model to ./\n",
      "INFO:tensorflow:Assets written to: ./assets\n",
      "98/98 [==============================] - 2s 21ms/step - loss: 42301.8125 - mae: 120.3044 - val_loss: 186922.8750 - val_mae: 152.7741\n",
      "Epoch 108/200\n",
      "90/98 [==========================>...] - ETA: 0s - loss: 40522.3789 - mae: 115.5734\n",
      "Epoch 108: val_loss improved from 186922.87500 to 183518.03125, saving model to ./\n",
      "INFO:tensorflow:Assets written to: ./assets\n",
      "98/98 [==============================] - 2s 16ms/step - loss: 40708.4531 - mae: 116.1968 - val_loss: 183518.0312 - val_mae: 148.0621\n",
      "Epoch 109/200\n",
      "90/98 [==========================>...] - ETA: 0s - loss: 40586.7500 - mae: 112.1412\n",
      "Epoch 109: val_loss improved from 183518.03125 to 179837.20312, saving model to ./\n",
      "INFO:tensorflow:Assets written to: ./assets\n",
      "98/98 [==============================] - 2s 17ms/step - loss: 39226.4766 - mae: 111.7852 - val_loss: 179837.2031 - val_mae: 143.2216\n",
      "Epoch 110/200\n",
      "84/98 [========================>.....] - ETA: 0s - loss: 40691.9727 - mae: 108.7733\n",
      "Epoch 110: val_loss improved from 179837.20312 to 176165.37500, saving model to ./\n",
      "INFO:tensorflow:Assets written to: ./assets\n",
      "98/98 [==============================] - 2s 17ms/step - loss: 37804.8672 - mae: 107.9033 - val_loss: 176165.3750 - val_mae: 138.8245\n",
      "Epoch 111/200\n",
      "88/98 [=========================>....] - ETA: 0s - loss: 34584.4766 - mae: 102.3305\n",
      "Epoch 111: val_loss improved from 176165.37500 to 172961.18750, saving model to ./\n",
      "INFO:tensorflow:Assets written to: ./assets\n",
      "98/98 [==============================] - 2s 17ms/step - loss: 36461.9570 - mae: 103.9917 - val_loss: 172961.1875 - val_mae: 134.2900\n",
      "Epoch 112/200\n",
      "88/98 [=========================>....] - ETA: 0s - loss: 35575.9023 - mae: 98.7106\n",
      "Epoch 112: val_loss improved from 172961.18750 to 169487.39062, saving model to ./\n",
      "INFO:tensorflow:Assets written to: ./assets\n",
      "98/98 [==============================] - 2s 16ms/step - loss: 35174.7812 - mae: 100.0816 - val_loss: 169487.3906 - val_mae: 130.0125\n",
      "Epoch 113/200\n",
      "83/98 [========================>.....] - ETA: 0s - loss: 35971.4219 - mae: 97.3498\n",
      "Epoch 113: val_loss improved from 169487.39062 to 166075.92188, saving model to ./\n",
      "INFO:tensorflow:Assets written to: ./assets\n",
      "98/98 [==============================] - 2s 21ms/step - loss: 33960.7852 - mae: 96.6133 - val_loss: 166075.9219 - val_mae: 125.8584\n",
      "Epoch 114/200\n",
      "91/98 [==========================>...] - ETA: 0s - loss: 31285.4043 - mae: 91.6974\n",
      "Epoch 114: val_loss improved from 166075.92188 to 162909.00000, saving model to ./\n",
      "INFO:tensorflow:Assets written to: ./assets\n",
      "98/98 [==============================] - 2s 16ms/step - loss: 32803.6758 - mae: 92.9435 - val_loss: 162909.0000 - val_mae: 121.6950\n",
      "Epoch 115/200\n",
      "88/98 [=========================>....] - ETA: 0s - loss: 33096.6133 - mae: 89.6165\n",
      "Epoch 115: val_loss improved from 162909.00000 to 159486.39062, saving model to ./\n",
      "INFO:tensorflow:Assets written to: ./assets\n",
      "98/98 [==============================] - 2s 16ms/step - loss: 31686.0469 - mae: 89.4761 - val_loss: 159486.3906 - val_mae: 118.0318\n",
      "Epoch 116/200\n",
      "87/98 [=========================>....] - ETA: 0s - loss: 32555.6699 - mae: 87.4169\n",
      "Epoch 116: val_loss improved from 159486.39062 to 156219.45312, saving model to ./\n",
      "INFO:tensorflow:Assets written to: ./assets\n",
      "98/98 [==============================] - 2s 17ms/step - loss: 30647.6816 - mae: 86.4516 - val_loss: 156219.4531 - val_mae: 114.4325\n",
      "Epoch 117/200\n",
      "82/98 [========================>.....] - ETA: 0s - loss: 27625.7051 - mae: 83.3281\n",
      "Epoch 117: val_loss improved from 156219.45312 to 153304.40625, saving model to ./\n",
      "INFO:tensorflow:Assets written to: ./assets\n",
      "98/98 [==============================] - 2s 17ms/step - loss: 29626.3789 - mae: 83.4204 - val_loss: 153304.4062 - val_mae: 110.9796\n",
      "Epoch 118/200\n",
      "86/98 [=========================>....] - ETA: 0s - loss: 30047.8105 - mae: 81.0071\n",
      "Epoch 118: val_loss improved from 153304.40625 to 149901.78125, saving model to ./\n",
      "INFO:tensorflow:Assets written to: ./assets\n",
      "98/98 [==============================] - 2s 16ms/step - loss: 28658.7969 - mae: 80.4533 - val_loss: 149901.7812 - val_mae: 107.4826\n",
      "Epoch 119/200\n",
      "89/98 [==========================>...] - ETA: 0s - loss: 28446.2109 - mae: 77.6817\n",
      "Epoch 119: val_loss improved from 149901.78125 to 145282.09375, saving model to ./\n",
      "INFO:tensorflow:Assets written to: ./assets\n",
      "98/98 [==============================] - 2s 21ms/step - loss: 27733.9961 - mae: 77.6302 - val_loss: 145282.0938 - val_mae: 104.1920\n",
      "Epoch 120/200\n",
      "86/98 [=========================>....] - ETA: 0s - loss: 29155.0898 - mae: 76.0810\n",
      "Epoch 120: val_loss improved from 145282.09375 to 133052.43750, saving model to ./\n",
      "INFO:tensorflow:Assets written to: ./assets\n",
      "98/98 [==============================] - 2s 17ms/step - loss: 26848.1113 - mae: 74.9740 - val_loss: 133052.4375 - val_mae: 100.3863\n",
      "Epoch 121/200\n",
      "90/98 [==========================>...] - ETA: 0s - loss: 26367.0527 - mae: 71.8315\n",
      "Epoch 121: val_loss improved from 133052.43750 to 97072.38281, saving model to ./\n",
      "INFO:tensorflow:Assets written to: ./assets\n",
      "98/98 [==============================] - 2s 16ms/step - loss: 25996.5820 - mae: 72.1565 - val_loss: 97072.3828 - val_mae: 94.5316\n",
      "Epoch 122/200\n",
      "84/98 [========================>.....] - ETA: 0s - loss: 19690.4336 - mae: 69.8198\n",
      "Epoch 122: val_loss improved from 97072.38281 to 49546.85156, saving model to ./\n",
      "INFO:tensorflow:Assets written to: ./assets\n",
      "98/98 [==============================] - 2s 17ms/step - loss: 25168.1387 - mae: 69.6178 - val_loss: 49546.8516 - val_mae: 86.3465\n",
      "Epoch 123/200\n",
      "84/98 [========================>.....] - ETA: 0s - loss: 26557.9258 - mae: 69.2936\n",
      "Epoch 123: val_loss improved from 49546.85156 to 31512.21680, saving model to ./\n",
      "INFO:tensorflow:Assets written to: ./assets\n",
      "98/98 [==============================] - 2s 16ms/step - loss: 24375.7227 - mae: 67.4496 - val_loss: 31512.2168 - val_mae: 80.9744\n",
      "Epoch 124/200\n",
      "89/98 [==========================>...] - ETA: 0s - loss: 24599.8574 - mae: 64.8961\n",
      "Epoch 124: val_loss improved from 31512.21680 to 25894.71289, saving model to ./\n",
      "INFO:tensorflow:Assets written to: ./assets\n",
      "98/98 [==============================] - 2s 17ms/step - loss: 23600.4863 - mae: 65.0843 - val_loss: 25894.7129 - val_mae: 77.1931\n",
      "Epoch 125/200\n",
      "87/98 [=========================>....] - ETA: 0s - loss: 20759.7441 - mae: 62.0059\n",
      "Epoch 125: val_loss improved from 25894.71289 to 22290.10547, saving model to ./\n",
      "INFO:tensorflow:Assets written to: ./assets\n",
      "98/98 [==============================] - 2s 21ms/step - loss: 22801.2988 - mae: 62.9075 - val_loss: 22290.1055 - val_mae: 73.8938\n",
      "Epoch 126/200\n",
      "74/98 [=====================>........] - ETA: 0s - loss: 26285.9199 - mae: 63.4010\n",
      "Epoch 126: val_loss improved from 22290.10547 to 18349.67773, saving model to ./\n",
      "INFO:tensorflow:Assets written to: ./assets\n",
      "98/98 [==============================] - 2s 16ms/step - loss: 22085.1660 - mae: 61.2551 - val_loss: 18349.6777 - val_mae: 69.7393\n",
      "Epoch 127/200\n",
      "88/98 [=========================>....] - ETA: 0s - loss: 22331.8730 - mae: 59.8931\n",
      "Epoch 127: val_loss improved from 18349.67773 to 17369.56836, saving model to ./\n",
      "INFO:tensorflow:Assets written to: ./assets\n",
      "98/98 [==============================] - 2s 16ms/step - loss: 21213.7305 - mae: 59.3521 - val_loss: 17369.5684 - val_mae: 67.0200\n",
      "Epoch 128/200\n",
      "83/98 [========================>.....] - ETA: 0s - loss: 20818.0625 - mae: 56.6144\n",
      "Epoch 128: val_loss improved from 17369.56836 to 16705.49414, saving model to ./\n",
      "INFO:tensorflow:Assets written to: ./assets\n",
      "98/98 [==============================] - 2s 16ms/step - loss: 20315.8164 - mae: 57.0748 - val_loss: 16705.4941 - val_mae: 64.6829\n",
      "Epoch 129/200\n",
      "92/98 [===========================>..] - ETA: 0s - loss: 19549.9395 - mae: 55.1096\n",
      "Epoch 129: val_loss improved from 16705.49414 to 16077.86230, saving model to ./\n",
      "INFO:tensorflow:Assets written to: ./assets\n",
      "98/98 [==============================] - 2s 17ms/step - loss: 19293.5488 - mae: 55.2718 - val_loss: 16077.8623 - val_mae: 62.7299\n",
      "Epoch 130/200\n",
      "88/98 [=========================>....] - ETA: 0s - loss: 19579.4238 - mae: 55.0551\n",
      "Epoch 130: val_loss improved from 16077.86230 to 15456.74512, saving model to ./\n",
      "INFO:tensorflow:Assets written to: ./assets\n",
      "98/98 [==============================] - 2s 17ms/step - loss: 18205.0879 - mae: 53.7001 - val_loss: 15456.7451 - val_mae: 60.9692\n",
      "Epoch 131/200\n",
      "89/98 [==========================>...] - ETA: 0s - loss: 16204.5664 - mae: 51.4306\n",
      "Epoch 131: val_loss improved from 15456.74512 to 14930.27734, saving model to ./\n",
      "INFO:tensorflow:Assets written to: ./assets\n",
      "98/98 [==============================] - 2s 21ms/step - loss: 17041.1289 - mae: 51.9843 - val_loss: 14930.2773 - val_mae: 59.1928\n",
      "Epoch 132/200\n",
      "86/98 [=========================>....] - ETA: 0s - loss: 17614.3828 - mae: 51.2247\n",
      "Epoch 132: val_loss improved from 14930.27734 to 14432.94629, saving model to ./\n",
      "INFO:tensorflow:Assets written to: ./assets\n",
      "98/98 [==============================] - 2s 17ms/step - loss: 16218.5410 - mae: 50.3981 - val_loss: 14432.9463 - val_mae: 57.9527\n",
      "Epoch 133/200\n",
      "88/98 [=========================>....] - ETA: 0s - loss: 15473.1533 - mae: 48.5039\n",
      "Epoch 133: val_loss did not improve from 14432.94629\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 15228.2988 - mae: 48.7282 - val_loss: 14510.5361 - val_mae: 57.2415\n",
      "Epoch 134/200\n",
      "86/98 [=========================>....] - ETA: 0s - loss: 14165.6309 - mae: 45.6785\n",
      "Epoch 134: val_loss did not improve from 14432.94629\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 14561.1396 - mae: 47.0186 - val_loss: 16592.2949 - val_mae: 57.3132\n",
      "Epoch 135/200\n",
      "87/98 [=========================>....] - ETA: 0s - loss: 14614.9141 - mae: 46.3107\n",
      "Epoch 135: val_loss did not improve from 14432.94629\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 14022.9912 - mae: 45.9705 - val_loss: 18342.4043 - val_mae: 56.8115\n",
      "Epoch 136/200\n",
      "92/98 [===========================>..] - ETA: 0s - loss: 14037.5664 - mae: 45.0275\n",
      "Epoch 136: val_loss did not improve from 14432.94629\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 13521.4902 - mae: 44.7109 - val_loss: 18550.2383 - val_mae: 55.7039\n",
      "Epoch 137/200\n",
      "84/98 [========================>.....] - ETA: 0s - loss: 12613.1846 - mae: 42.6664\n",
      "Epoch 137: val_loss did not improve from 14432.94629\n",
      "98/98 [==============================] - 0s 3ms/step - loss: 13071.0791 - mae: 43.4521 - val_loss: 18247.8223 - val_mae: 54.4385\n",
      "Epoch 138/200\n",
      "90/98 [==========================>...] - ETA: 0s - loss: 7820.1577 - mae: 40.7549\n",
      "Epoch 138: val_loss did not improve from 14432.94629\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 12646.7764 - mae: 42.1788 - val_loss: 17853.8027 - val_mae: 53.1493\n",
      "Epoch 139/200\n",
      "92/98 [===========================>..] - ETA: 0s - loss: 12468.7627 - mae: 40.9134\n",
      "Epoch 139: val_loss did not improve from 14432.94629\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 12239.8486 - mae: 41.4563 - val_loss: 17197.4414 - val_mae: 52.0115\n",
      "Epoch 140/200\n",
      "87/98 [=========================>....] - ETA: 0s - loss: 10223.1230 - mae: 38.4045\n",
      "Epoch 140: val_loss did not improve from 14432.94629\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 11835.9238 - mae: 40.3988 - val_loss: 16544.2480 - val_mae: 50.6622\n",
      "Epoch 141/200\n",
      "92/98 [===========================>..] - ETA: 0s - loss: 11854.0840 - mae: 40.0173\n",
      "Epoch 141: val_loss did not improve from 14432.94629\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 11459.0586 - mae: 39.6118 - val_loss: 15618.6377 - val_mae: 49.4632\n",
      "Epoch 142/200\n",
      "88/98 [=========================>....] - ETA: 0s - loss: 11013.0479 - mae: 37.8713\n",
      "Epoch 142: val_loss did not improve from 14432.94629\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 11071.6631 - mae: 38.5409 - val_loss: 14536.8096 - val_mae: 48.0686\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from keras.layers import LSTM\n",
    "\n",
    "model = Sequential()\n",
    "model.add(LSTM(16, \n",
    "               input_shape=(train_feature.shape[1], train_feature.shape[2]), \n",
    "               activation='relu', \n",
    "               return_sequences=False)\n",
    "          )\n",
    "model.add(Dense(1))\n",
    "\n",
    "model.compile(loss='mean_squared_error', optimizer='adam', metrics=['mae'])\n",
    "early_stop = EarlyStopping(monitor='val_loss', patience=10)\n",
    "modelpath = './'\n",
    "checkpoint = ModelCheckpoint(filepath=modelpath, monitor='val_loss', verbose=1, save_best_only=True, mode='auto')\n",
    "# filename = os.path.join(file_path=model_path, 'tmp_checkpoint.h5')\n",
    "\n",
    "history = model.fit(x_train, y_train, \n",
    "                    epochs=200, \n",
    "                    batch_size=16,\n",
    "                    validation_data=(x_valid, y_valid), \n",
    "                    callbacks=[early_stop, checkpoint])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.5 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
