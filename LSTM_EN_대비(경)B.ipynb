{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import warnings \n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# 파일 불러오기\n",
    "df = pd.read_excel(\"../데이터자료/Join_data.xlsx\", index_col = 0)    \n",
    "df = df.set_index(\"DateTime\")\n",
    "\n",
    "# 대비 계산\n",
    "df['대비_irs_1Y'] = df['1Y_Mid_irs'] - df['1Y_Mid_irs'].shift(1) \n",
    "df['대비_irs_2Y'] = df['2Y_Mid_irs'] - df['2Y_Mid_irs'].shift(1) \n",
    "df['대비_irs_3Y'] = df['3Y_Mid_irs'] - df['3Y_Mid_irs'].shift(1) \n",
    "df['대비_irs_5Y'] = df['5Y_Mid_irs'] - df['5Y_Mid_irs'].shift(1) \n",
    "df['대비_irs_10Y'] = df['10Y_Mid_irs'] - df['10Y_Mid_irs'].shift(1) \n",
    "\n",
    "df['대비_crs_1Y'] = df['1Y_Mid_crs'] - df['1Y_Mid_crs'].shift(1)\n",
    "df['대비_crs_2Y'] = df['2Y_Mid_crs'] - df['2Y_Mid_crs'].shift(1)\n",
    "df['대비_crs_3Y'] = df['3Y_Mid_crs'] - df['3Y_Mid_crs'].shift(1)\n",
    "df['대비_crs_5Y'] = df['5Y_Mid_crs'] - df['5Y_Mid_crs'].shift(1)\n",
    "df['대비_crs_10Y'] = df['10Y_Mid_crs'] - df['10Y_Mid_crs'].shift(1)\n",
    "\n",
    "df['대비_swapbasis_1Y'] = df['1Y_베이시스']-df['1Y_베이시스'].shift(1)\n",
    "df['대비_swapbasis_2Y'] = df['2Y_베이시스']-df['2Y_베이시스'].shift(1)\n",
    "df['대비_swapbasis_3Y'] = df['3Y_베이시스']-df['3Y_베이시스'].shift(1)\n",
    "df['대비_swapbasis_5Y'] = df['5Y_베이시스']-df['5Y_베이시스'].shift(1)\n",
    "df['대비_swapbasis_10Y'] = df['10Y_베이시스']-df['10Y_베이시스'].shift(1)\n",
    "\n",
    "df['대비_국고_1Y'] = df['국고1년']-df['국고1년'].shift(1)\n",
    "df['대비_국고_3Y'] = df['국고3년']-df['국고3년'].shift(1)\n",
    "df['대비_국고_5Y'] = df['국고5년']-df['국고5년'].shift(1)\n",
    "df['대비_국고_10Y'] = df['국고10년']-df['국고10년'].shift(1)\n",
    "\n",
    "df['대비_통안_1Y'] = df['통안364일']-df['통안364일'].shift(1)\n",
    "df['대비_통안_2Y'] = df['통안2년']-df['통안2년'].shift(1)\n",
    "\n",
    "df['대비_ndf'] = df['Mid_ndf']-df['Mid_ndf'].shift(1)\n",
    "df['스왑포인트_1M'] = df[\"M1_스왑포인트\"]/100 \n",
    "df['전일종가_ex'] = df['종가_ex'].shift(1)\n",
    "df['종가_NDF_차이'] = df['전일종가_ex'] - df['Mid_ndf']\n",
    "\n",
    "# 필요한 칼럼만 추출\n",
    "df_1 = df[['대비_irs_1Y', '대비_irs_2Y', '대비_irs_3Y', '대비_irs_5Y', '대비_irs_10Y',\n",
    "           '대비_crs_1Y', '대비_crs_2Y', '대비_crs_3Y', '대비_crs_5Y', '대비_crs_10Y', \n",
    "           '대비_swapbasis_1Y', '대비_swapbasis_2Y', '대비_swapbasis_3Y', '대비_swapbasis_5Y', '대비_swapbasis_10Y',\n",
    "           '대비_국고_1Y', '대비_국고_3Y', '대비_국고_5Y', '대비_국고_10Y', \n",
    "           '대비_통안_1Y', '대비_통안_2Y', '대비_ndf', '스왑포인트_1M', '전일종가_ex', \n",
    "           '종가_ex', '종가_NDF_차이' ]] \n",
    "\n",
    "# 결측치 제거\n",
    "df_1 = df_1.dropna()                        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>대비_swapbasis_1Y</th>\n",
       "      <th>대비_swapbasis_2Y</th>\n",
       "      <th>대비_swapbasis_3Y</th>\n",
       "      <th>대비_swapbasis_5Y</th>\n",
       "      <th>대비_swapbasis_10Y</th>\n",
       "      <th>대비_국고_1Y</th>\n",
       "      <th>대비_국고_3Y</th>\n",
       "      <th>대비_국고_5Y</th>\n",
       "      <th>대비_국고_10Y</th>\n",
       "      <th>대비_통안_1Y</th>\n",
       "      <th>대비_통안_2Y</th>\n",
       "      <th>스왑포인트_1M</th>\n",
       "      <th>전일종가_ex</th>\n",
       "      <th>종가_NDF_차이</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DateTime</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2012-08-02</th>\n",
       "      <td>0.348741</td>\n",
       "      <td>1.544080</td>\n",
       "      <td>1.437744</td>\n",
       "      <td>1.627899</td>\n",
       "      <td>1.488363</td>\n",
       "      <td>-1.698057</td>\n",
       "      <td>-0.646622</td>\n",
       "      <td>-1.079749</td>\n",
       "      <td>-1.027569</td>\n",
       "      <td>-0.325920</td>\n",
       "      <td>-0.625160</td>\n",
       "      <td>1.909409</td>\n",
       "      <td>-0.149841</td>\n",
       "      <td>-1.648743</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2012-08-03</th>\n",
       "      <td>0.348741</td>\n",
       "      <td>0.286831</td>\n",
       "      <td>0.157058</td>\n",
       "      <td>-0.910410</td>\n",
       "      <td>-2.158344</td>\n",
       "      <td>-1.132651</td>\n",
       "      <td>-0.323869</td>\n",
       "      <td>-1.890219</td>\n",
       "      <td>-1.798403</td>\n",
       "      <td>-0.217574</td>\n",
       "      <td>-0.125723</td>\n",
       "      <td>1.818881</td>\n",
       "      <td>-0.056232</td>\n",
       "      <td>-1.366022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2012-08-06</th>\n",
       "      <td>-0.350946</td>\n",
       "      <td>-0.873707</td>\n",
       "      <td>-0.803456</td>\n",
       "      <td>-1.091718</td>\n",
       "      <td>-0.832269</td>\n",
       "      <td>0.563566</td>\n",
       "      <td>0.160261</td>\n",
       "      <td>0.000879</td>\n",
       "      <td>0.000209</td>\n",
       "      <td>0.107465</td>\n",
       "      <td>0.123996</td>\n",
       "      <td>1.818881</td>\n",
       "      <td>-0.000426</td>\n",
       "      <td>1.602547</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2012-08-07</th>\n",
       "      <td>0.173819</td>\n",
       "      <td>0.286831</td>\n",
       "      <td>-0.003027</td>\n",
       "      <td>-1.454333</td>\n",
       "      <td>-1.661066</td>\n",
       "      <td>-0.567245</td>\n",
       "      <td>-0.001116</td>\n",
       "      <td>0.000879</td>\n",
       "      <td>0.000209</td>\n",
       "      <td>-0.109228</td>\n",
       "      <td>-0.125723</td>\n",
       "      <td>1.909409</td>\n",
       "      <td>-0.104837</td>\n",
       "      <td>0.118263</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2012-08-08</th>\n",
       "      <td>-0.001103</td>\n",
       "      <td>-0.390150</td>\n",
       "      <td>-0.323199</td>\n",
       "      <td>-0.729102</td>\n",
       "      <td>-1.163788</td>\n",
       "      <td>-0.567245</td>\n",
       "      <td>-0.323869</td>\n",
       "      <td>-0.539435</td>\n",
       "      <td>-0.513680</td>\n",
       "      <td>-0.109228</td>\n",
       "      <td>-0.125723</td>\n",
       "      <td>1.818881</td>\n",
       "      <td>-0.108437</td>\n",
       "      <td>-0.223358</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-07-25</th>\n",
       "      <td>-0.700790</td>\n",
       "      <td>-0.196727</td>\n",
       "      <td>-0.003027</td>\n",
       "      <td>-0.366487</td>\n",
       "      <td>-0.003472</td>\n",
       "      <td>-1.132651</td>\n",
       "      <td>-0.969375</td>\n",
       "      <td>-1.890219</td>\n",
       "      <td>-2.312292</td>\n",
       "      <td>-0.109228</td>\n",
       "      <td>-0.625160</td>\n",
       "      <td>-0.896960</td>\n",
       "      <td>3.207485</td>\n",
       "      <td>0.860405</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-07-26</th>\n",
       "      <td>0.348741</td>\n",
       "      <td>-0.196727</td>\n",
       "      <td>-0.003027</td>\n",
       "      <td>0.177437</td>\n",
       "      <td>0.162288</td>\n",
       "      <td>0.563566</td>\n",
       "      <td>-0.485246</td>\n",
       "      <td>-0.539435</td>\n",
       "      <td>-0.770625</td>\n",
       "      <td>0.107465</td>\n",
       "      <td>-0.000863</td>\n",
       "      <td>-0.987488</td>\n",
       "      <td>3.220086</td>\n",
       "      <td>0.754385</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-07-27</th>\n",
       "      <td>0.348741</td>\n",
       "      <td>0.770388</td>\n",
       "      <td>0.797401</td>\n",
       "      <td>0.902668</td>\n",
       "      <td>0.825326</td>\n",
       "      <td>-0.001839</td>\n",
       "      <td>-0.485246</td>\n",
       "      <td>-1.349905</td>\n",
       "      <td>-1.541458</td>\n",
       "      <td>0.215812</td>\n",
       "      <td>-0.125723</td>\n",
       "      <td>-0.851696</td>\n",
       "      <td>3.110275</td>\n",
       "      <td>-0.564979</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-07-28</th>\n",
       "      <td>0.173819</td>\n",
       "      <td>-0.003304</td>\n",
       "      <td>-0.163113</td>\n",
       "      <td>-0.366487</td>\n",
       "      <td>-0.832269</td>\n",
       "      <td>0.563566</td>\n",
       "      <td>0.644391</td>\n",
       "      <td>0.811350</td>\n",
       "      <td>2.055766</td>\n",
       "      <td>0.215812</td>\n",
       "      <td>0.373715</td>\n",
       "      <td>-0.942224</td>\n",
       "      <td>3.212885</td>\n",
       "      <td>1.838148</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-07-29</th>\n",
       "      <td>-0.700790</td>\n",
       "      <td>-0.583573</td>\n",
       "      <td>-0.163113</td>\n",
       "      <td>0.902668</td>\n",
       "      <td>0.493807</td>\n",
       "      <td>-2.263463</td>\n",
       "      <td>-2.099012</td>\n",
       "      <td>-3.241004</td>\n",
       "      <td>-2.055348</td>\n",
       "      <td>-0.325920</td>\n",
       "      <td>-1.374316</td>\n",
       "      <td>-0.896960</td>\n",
       "      <td>2.903255</td>\n",
       "      <td>0.200723</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2459 rows × 14 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            대비_swapbasis_1Y  대비_swapbasis_2Y  대비_swapbasis_3Y  \\\n",
       "DateTime                                                        \n",
       "2012-08-02         0.348741         1.544080         1.437744   \n",
       "2012-08-03         0.348741         0.286831         0.157058   \n",
       "2012-08-06        -0.350946        -0.873707        -0.803456   \n",
       "2012-08-07         0.173819         0.286831        -0.003027   \n",
       "2012-08-08        -0.001103        -0.390150        -0.323199   \n",
       "...                     ...              ...              ...   \n",
       "2022-07-25        -0.700790        -0.196727        -0.003027   \n",
       "2022-07-26         0.348741        -0.196727        -0.003027   \n",
       "2022-07-27         0.348741         0.770388         0.797401   \n",
       "2022-07-28         0.173819        -0.003304        -0.163113   \n",
       "2022-07-29        -0.700790        -0.583573        -0.163113   \n",
       "\n",
       "            대비_swapbasis_5Y  대비_swapbasis_10Y  대비_국고_1Y  대비_국고_3Y  대비_국고_5Y  \\\n",
       "DateTime                                                                      \n",
       "2012-08-02         1.627899          1.488363 -1.698057 -0.646622 -1.079749   \n",
       "2012-08-03        -0.910410         -2.158344 -1.132651 -0.323869 -1.890219   \n",
       "2012-08-06        -1.091718         -0.832269  0.563566  0.160261  0.000879   \n",
       "2012-08-07        -1.454333         -1.661066 -0.567245 -0.001116  0.000879   \n",
       "2012-08-08        -0.729102         -1.163788 -0.567245 -0.323869 -0.539435   \n",
       "...                     ...               ...       ...       ...       ...   \n",
       "2022-07-25        -0.366487         -0.003472 -1.132651 -0.969375 -1.890219   \n",
       "2022-07-26         0.177437          0.162288  0.563566 -0.485246 -0.539435   \n",
       "2022-07-27         0.902668          0.825326 -0.001839 -0.485246 -1.349905   \n",
       "2022-07-28        -0.366487         -0.832269  0.563566  0.644391  0.811350   \n",
       "2022-07-29         0.902668          0.493807 -2.263463 -2.099012 -3.241004   \n",
       "\n",
       "            대비_국고_10Y  대비_통안_1Y  대비_통안_2Y  스왑포인트_1M   전일종가_ex  종가_NDF_차이  \n",
       "DateTime                                                                  \n",
       "2012-08-02  -1.027569 -0.325920 -0.625160  1.909409 -0.149841  -1.648743  \n",
       "2012-08-03  -1.798403 -0.217574 -0.125723  1.818881 -0.056232  -1.366022  \n",
       "2012-08-06   0.000209  0.107465  0.123996  1.818881 -0.000426   1.602547  \n",
       "2012-08-07   0.000209 -0.109228 -0.125723  1.909409 -0.104837   0.118263  \n",
       "2012-08-08  -0.513680 -0.109228 -0.125723  1.818881 -0.108437  -0.223358  \n",
       "...               ...       ...       ...       ...       ...        ...  \n",
       "2022-07-25  -2.312292 -0.109228 -0.625160 -0.896960  3.207485   0.860405  \n",
       "2022-07-26  -0.770625  0.107465 -0.000863 -0.987488  3.220086   0.754385  \n",
       "2022-07-27  -1.541458  0.215812 -0.125723 -0.851696  3.110275  -0.564979  \n",
       "2022-07-28   2.055766  0.215812  0.373715 -0.942224  3.212885   1.838148  \n",
       "2022-07-29  -2.055348 -0.325920 -1.374316 -0.896960  2.903255   0.200723  \n",
       "\n",
       "[2459 rows x 14 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# 쓸 칼럼만 남기고 feature, target 분리해 각각 x,y 에 저장\n",
    "x = df_1[[ '대비_swapbasis_1Y', '대비_swapbasis_2Y', '대비_swapbasis_3Y', '대비_swapbasis_5Y', '대비_swapbasis_10Y',\n",
    "           '대비_국고_1Y', '대비_국고_3Y', '대비_국고_5Y', '대비_국고_10Y', \n",
    "           '대비_통안_1Y', '대비_통안_2Y', '스왑포인트_1M', '전일종가_ex', \n",
    "           '종가_NDF_차이']]\n",
    "y = df_1[['종가_ex']]\n",
    "\n",
    "# 이건 이렇게 해야 밑에 코드 8번째 줄 columns에 들어갈 수 있다고 하네요!\n",
    "x.feature = x.columns \n",
    "x.feature\n",
    "\n",
    "# scaling 진행\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# MinMaxScaler객체 생성\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# MinMaxScaler 로 데이터 셋 변환. fit() 과 transform() 호출.\n",
    "scaler.fit(x)\n",
    "data_scaled = scaler.transform(x)\n",
    "\n",
    "# transform()시 scale 변환된 데이터 셋이 numpy ndarry로 반환되어 이를 DataFrame으로 변환\n",
    "x_scaled = pd.DataFrame(data = data_scaled, columns=x.feature)\n",
    "x_scaled.index = y.index # 인덱스가 달라서 똑같이 설정\n",
    "\n",
    "x_scaled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    VIF_Factor           Feature\n",
      "0     3.169185   대비_swapbasis_1Y\n",
      "1     5.912724   대비_swapbasis_2Y\n",
      "2     2.407206   대비_swapbasis_3Y\n",
      "3     4.772400   대비_swapbasis_5Y\n",
      "4     3.269360  대비_swapbasis_10Y\n",
      "5     1.830986          대비_국고_1Y\n",
      "6     1.245142          대비_국고_3Y\n",
      "7     5.830426          대비_국고_5Y\n",
      "8     4.886685         대비_국고_10Y\n",
      "9     1.024620          대비_통안_1Y\n",
      "10    1.114166          대비_통안_2Y\n",
      "11    1.246756          스왑포인트_1M\n",
      "12    1.189179           전일종가_ex\n",
      "13    1.150172         종가_NDF_차이\n"
     ]
    }
   ],
   "source": [
    "from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
    "X_train = x_scaled\n",
    "\n",
    "def feature_engineering_XbyVIF(X_train):\n",
    "    vif = pd.DataFrame()\n",
    "    vif[\"VIF_Factor\"] = [variance_inflation_factor(X_train.values,i)\n",
    "                         for i in range(X_train.shape[1])]\n",
    "    vif[\"Feature\"] = X_train.columns\n",
    "    return vif\n",
    "vif = feature_engineering_XbyVIF(X_train)\n",
    "print(vif)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>          <td>종가_ex</td>      <th>  R-squared:         </th> <td>   0.995</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th> <td>   0.995</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th> <td>3.260e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Mon, 17 Oct 2022</td> <th>  Prob (F-statistic):</th>  <td>  0.00</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>17:15:06</td>     <th>  Log-Likelihood:    </th> <td> -6935.6</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td>  2459</td>      <th>  AIC:               </th> <td>1.390e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td>  2444</td>      <th>  BIC:               </th> <td>1.399e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>    14</td>      <th>                     </th>     <td> </td>    \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>     <td> </td>    \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "          <td></td>            <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>const</th>            <td> 1134.8939</td> <td>    0.082</td> <td> 1.38e+04</td> <td> 0.000</td> <td> 1134.733</td> <td> 1135.055</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>대비_swapbasis_1Y</th>  <td>   -0.8203</td> <td>    0.146</td> <td>   -5.609</td> <td> 0.000</td> <td>   -1.107</td> <td>   -0.534</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>대비_swapbasis_2Y</th>  <td>    0.0651</td> <td>    0.200</td> <td>    0.326</td> <td> 0.744</td> <td>   -0.327</td> <td>    0.457</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>대비_swapbasis_3Y</th>  <td>   -0.1486</td> <td>    0.127</td> <td>   -1.166</td> <td> 0.244</td> <td>   -0.399</td> <td>    0.101</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>대비_swapbasis_5Y</th>  <td>   -0.1569</td> <td>    0.179</td> <td>   -0.874</td> <td> 0.382</td> <td>   -0.509</td> <td>    0.195</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>대비_swapbasis_10Y</th> <td>    0.2510</td> <td>    0.149</td> <td>    1.690</td> <td> 0.091</td> <td>   -0.040</td> <td>    0.542</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>대비_국고_1Y</th>         <td>   -0.0954</td> <td>    0.111</td> <td>   -0.858</td> <td> 0.391</td> <td>   -0.313</td> <td>    0.123</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>대비_국고_3Y</th>         <td>   -0.1922</td> <td>    0.092</td> <td>   -2.096</td> <td> 0.036</td> <td>   -0.372</td> <td>   -0.012</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>대비_국고_5Y</th>         <td>   -0.0157</td> <td>    0.198</td> <td>   -0.079</td> <td> 0.937</td> <td>   -0.405</td> <td>    0.373</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>대비_국고_10Y</th>        <td>   -0.0323</td> <td>    0.182</td> <td>   -0.178</td> <td> 0.859</td> <td>   -0.388</td> <td>    0.324</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>대비_통안_1Y</th>         <td>   -0.0087</td> <td>    0.083</td> <td>   -0.104</td> <td> 0.917</td> <td>   -0.172</td> <td>    0.154</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>대비_통안_2Y</th>         <td>    0.0318</td> <td>    0.087</td> <td>    0.367</td> <td> 0.713</td> <td>   -0.138</td> <td>    0.202</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>스왑포인트_1M</th>         <td>   -1.1897</td> <td>    0.092</td> <td>  -12.969</td> <td> 0.000</td> <td>   -1.370</td> <td>   -1.010</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>전일종가_ex</th>          <td>   55.7341</td> <td>    0.090</td> <td>  622.093</td> <td> 0.000</td> <td>   55.558</td> <td>   55.910</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>종가_NDF_차이</th>        <td>   -4.0157</td> <td>    0.088</td> <td>  -45.576</td> <td> 0.000</td> <td>   -4.188</td> <td>   -3.843</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td>243.950</td> <th>  Durbin-Watson:     </th> <td>   2.099</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th> <td> 0.000</td>  <th>  Jarque-Bera (JB):  </th> <td>1184.432</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>          <td> 0.349</td>  <th>  Prob(JB):          </th> <td>6.36e-258</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>      <td> 6.328</td>  <th>  Cond. No.          </th> <td>    6.54</td> \n",
       "</tr>\n",
       "</table><br/><br/>Notes:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified."
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                            OLS Regression Results                            \n",
       "==============================================================================\n",
       "Dep. Variable:                  종가_ex   R-squared:                       0.995\n",
       "Model:                            OLS   Adj. R-squared:                  0.995\n",
       "Method:                 Least Squares   F-statistic:                 3.260e+04\n",
       "Date:                Mon, 17 Oct 2022   Prob (F-statistic):               0.00\n",
       "Time:                        17:15:06   Log-Likelihood:                -6935.6\n",
       "No. Observations:                2459   AIC:                         1.390e+04\n",
       "Df Residuals:                    2444   BIC:                         1.399e+04\n",
       "Df Model:                          14                                         \n",
       "Covariance Type:            nonrobust                                         \n",
       "====================================================================================\n",
       "                       coef    std err          t      P>|t|      [0.025      0.975]\n",
       "------------------------------------------------------------------------------------\n",
       "const             1134.8939      0.082   1.38e+04      0.000    1134.733    1135.055\n",
       "대비_swapbasis_1Y     -0.8203      0.146     -5.609      0.000      -1.107      -0.534\n",
       "대비_swapbasis_2Y      0.0651      0.200      0.326      0.744      -0.327       0.457\n",
       "대비_swapbasis_3Y     -0.1486      0.127     -1.166      0.244      -0.399       0.101\n",
       "대비_swapbasis_5Y     -0.1569      0.179     -0.874      0.382      -0.509       0.195\n",
       "대비_swapbasis_10Y     0.2510      0.149      1.690      0.091      -0.040       0.542\n",
       "대비_국고_1Y            -0.0954      0.111     -0.858      0.391      -0.313       0.123\n",
       "대비_국고_3Y            -0.1922      0.092     -2.096      0.036      -0.372      -0.012\n",
       "대비_국고_5Y            -0.0157      0.198     -0.079      0.937      -0.405       0.373\n",
       "대비_국고_10Y           -0.0323      0.182     -0.178      0.859      -0.388       0.324\n",
       "대비_통안_1Y            -0.0087      0.083     -0.104      0.917      -0.172       0.154\n",
       "대비_통안_2Y             0.0318      0.087      0.367      0.713      -0.138       0.202\n",
       "스왑포인트_1M            -1.1897      0.092    -12.969      0.000      -1.370      -1.010\n",
       "전일종가_ex             55.7341      0.090    622.093      0.000      55.558      55.910\n",
       "종가_NDF_차이           -4.0157      0.088    -45.576      0.000      -4.188      -3.843\n",
       "==============================================================================\n",
       "Omnibus:                      243.950   Durbin-Watson:                   2.099\n",
       "Prob(Omnibus):                  0.000   Jarque-Bera (JB):             1184.432\n",
       "Skew:                           0.349   Prob(JB):                    6.36e-258\n",
       "Kurtosis:                       6.328   Cond. No.                         6.54\n",
       "==============================================================================\n",
       "\n",
       "Notes:\n",
       "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "\"\"\""
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import statsmodels.api as sm\n",
    "\n",
    "feature_add = sm.add_constant(x_scaled, has_constant='add')\n",
    "\n",
    "# sm OLS 적합\n",
    "model = sm.OLS(y , feature_add)\n",
    "fitted_model = model.fit()\n",
    "\n",
    "# summary 함수통해 결과출력\n",
    "fitted_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>          <td>종가_ex</td>      <th>  R-squared:         </th> <td>   0.995</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th> <td>   0.995</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th> <td>4.149e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Mon, 17 Oct 2022</td> <th>  Prob (F-statistic):</th>  <td>  0.00</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>17:15:07</td>     <th>  Log-Likelihood:    </th> <td> -6937.0</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td>  2459</td>      <th>  AIC:               </th> <td>1.390e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td>  2447</td>      <th>  BIC:               </th> <td>1.397e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>    11</td>      <th>                     </th>     <td> </td>    \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>     <td> </td>    \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "          <td></td>            <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>const</th>            <td> 1134.8939</td> <td>    0.082</td> <td> 1.38e+04</td> <td> 0.000</td> <td> 1134.733</td> <td> 1135.055</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>대비_swapbasis_1Y</th>  <td>   -0.8915</td> <td>    0.107</td> <td>   -8.341</td> <td> 0.000</td> <td>   -1.101</td> <td>   -0.682</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>대비_swapbasis_10Y</th> <td>    0.1240</td> <td>    0.109</td> <td>    1.139</td> <td> 0.255</td> <td>   -0.090</td> <td>    0.338</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>대비_국고_1Y</th>         <td>   -0.0886</td> <td>    0.111</td> <td>   -0.798</td> <td> 0.425</td> <td>   -0.306</td> <td>    0.129</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>대비_국고_3Y</th>         <td>   -0.1890</td> <td>    0.092</td> <td>   -2.064</td> <td> 0.039</td> <td>   -0.369</td> <td>   -0.009</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>대비_국고_5Y</th>         <td>   -0.0047</td> <td>    0.198</td> <td>   -0.024</td> <td> 0.981</td> <td>   -0.393</td> <td>    0.384</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>대비_국고_10Y</th>        <td>   -0.0347</td> <td>    0.182</td> <td>   -0.191</td> <td> 0.848</td> <td>   -0.391</td> <td>    0.321</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>대비_통안_1Y</th>         <td>   -0.0084</td> <td>    0.083</td> <td>   -0.101</td> <td> 0.919</td> <td>   -0.171</td> <td>    0.155</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>대비_통안_2Y</th>         <td>    0.0340</td> <td>    0.087</td> <td>    0.392</td> <td> 0.695</td> <td>   -0.136</td> <td>    0.204</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>스왑포인트_1M</th>         <td>   -1.1893</td> <td>    0.092</td> <td>  -12.966</td> <td> 0.000</td> <td>   -1.369</td> <td>   -1.009</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>전일종가_ex</th>          <td>   55.7336</td> <td>    0.090</td> <td>  622.137</td> <td> 0.000</td> <td>   55.558</td> <td>   55.909</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>종가_NDF_차이</th>        <td>   -4.0131</td> <td>    0.088</td> <td>  -45.583</td> <td> 0.000</td> <td>   -4.186</td> <td>   -3.840</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td>245.412</td> <th>  Durbin-Watson:     </th> <td>   2.095</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th> <td> 0.000</td>  <th>  Jarque-Bera (JB):  </th> <td>1189.383</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>          <td> 0.354</td>  <th>  Prob(JB):          </th> <td>5.36e-259</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>      <td> 6.333</td>  <th>  Cond. No.          </th> <td>    5.43</td> \n",
       "</tr>\n",
       "</table><br/><br/>Notes:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified."
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                            OLS Regression Results                            \n",
       "==============================================================================\n",
       "Dep. Variable:                  종가_ex   R-squared:                       0.995\n",
       "Model:                            OLS   Adj. R-squared:                  0.995\n",
       "Method:                 Least Squares   F-statistic:                 4.149e+04\n",
       "Date:                Mon, 17 Oct 2022   Prob (F-statistic):               0.00\n",
       "Time:                        17:15:07   Log-Likelihood:                -6937.0\n",
       "No. Observations:                2459   AIC:                         1.390e+04\n",
       "Df Residuals:                    2447   BIC:                         1.397e+04\n",
       "Df Model:                          11                                         \n",
       "Covariance Type:            nonrobust                                         \n",
       "====================================================================================\n",
       "                       coef    std err          t      P>|t|      [0.025      0.975]\n",
       "------------------------------------------------------------------------------------\n",
       "const             1134.8939      0.082   1.38e+04      0.000    1134.733    1135.055\n",
       "대비_swapbasis_1Y     -0.8915      0.107     -8.341      0.000      -1.101      -0.682\n",
       "대비_swapbasis_10Y     0.1240      0.109      1.139      0.255      -0.090       0.338\n",
       "대비_국고_1Y            -0.0886      0.111     -0.798      0.425      -0.306       0.129\n",
       "대비_국고_3Y            -0.1890      0.092     -2.064      0.039      -0.369      -0.009\n",
       "대비_국고_5Y            -0.0047      0.198     -0.024      0.981      -0.393       0.384\n",
       "대비_국고_10Y           -0.0347      0.182     -0.191      0.848      -0.391       0.321\n",
       "대비_통안_1Y            -0.0084      0.083     -0.101      0.919      -0.171       0.155\n",
       "대비_통안_2Y             0.0340      0.087      0.392      0.695      -0.136       0.204\n",
       "스왑포인트_1M            -1.1893      0.092    -12.966      0.000      -1.369      -1.009\n",
       "전일종가_ex             55.7336      0.090    622.137      0.000      55.558      55.909\n",
       "종가_NDF_차이           -4.0131      0.088    -45.583      0.000      -4.186      -3.840\n",
       "==============================================================================\n",
       "Omnibus:                      245.412   Durbin-Watson:                   2.095\n",
       "Prob(Omnibus):                  0.000   Jarque-Bera (JB):             1189.383\n",
       "Skew:                           0.354   Prob(JB):                    5.36e-259\n",
       "Kurtosis:                       6.333   Cond. No.                         5.43\n",
       "==============================================================================\n",
       "\n",
       "Notes:\n",
       "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "\"\"\""
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_scaled.drop(['대비_swapbasis_2Y', '대비_swapbasis_3Y', '대비_swapbasis_5Y'], axis=1, inplace=True)\n",
    "\n",
    "feature_add = sm.add_constant(x_scaled, has_constant='add')\n",
    "\n",
    "# sm OLS 적합\n",
    "model = sm.OLS(y , feature_add)\n",
    "fitted_model = model.fit()\n",
    "\n",
    "# summary 함수통해 결과출력\n",
    "fitted_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   VIF_Factor           Feature\n",
      "0    1.692389   대비_swapbasis_1Y\n",
      "1    1.757274  대비_swapbasis_10Y\n",
      "2    1.814188          대비_국고_1Y\n",
      "3    1.243174          대비_국고_3Y\n",
      "4    5.812902          대비_국고_5Y\n",
      "5    4.882217         대비_국고_10Y\n",
      "6    1.113392          대비_통안_2Y\n",
      "7    1.246520          스왑포인트_1M\n",
      "8    1.189005           전일종가_ex\n",
      "9    1.148435         종가_NDF_차이\n"
     ]
    }
   ],
   "source": [
    "x_scaled.drop(['대비_통안_1Y'], axis=1, inplace=True)\n",
    "\n",
    "from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
    "X_train = x_scaled\n",
    "def feature_engineering_XbyVIF(X_train):\n",
    "    vif = pd.DataFrame()\n",
    "    vif[\"VIF_Factor\"] = [variance_inflation_factor(X_train.values,i)\n",
    "                         for i in range(X_train.shape[1])]\n",
    "    vif[\"Feature\"] = X_train.columns\n",
    "    return vif\n",
    "vif = feature_engineering_XbyVIF(X_train)\n",
    "print(vif)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>          <td>종가_ex</td>      <th>  R-squared:         </th> <td>   0.995</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th> <td>   0.995</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th> <td>4.566e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Mon, 17 Oct 2022</td> <th>  Prob (F-statistic):</th>  <td>  0.00</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>17:15:08</td>     <th>  Log-Likelihood:    </th> <td> -6937.0</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td>  2459</td>      <th>  AIC:               </th> <td>1.390e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td>  2448</td>      <th>  BIC:               </th> <td>1.396e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>    10</td>      <th>                     </th>     <td> </td>    \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>     <td> </td>    \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "          <td></td>            <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>const</th>            <td> 1134.8939</td> <td>    0.082</td> <td> 1.38e+04</td> <td> 0.000</td> <td> 1134.733</td> <td> 1135.055</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>대비_swapbasis_1Y</th>  <td>   -0.8914</td> <td>    0.107</td> <td>   -8.343</td> <td> 0.000</td> <td>   -1.101</td> <td>   -0.682</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>대비_swapbasis_10Y</th> <td>    0.1240</td> <td>    0.109</td> <td>    1.139</td> <td> 0.255</td> <td>   -0.090</td> <td>    0.337</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>대비_국고_1Y</th>         <td>   -0.0895</td> <td>    0.111</td> <td>   -0.809</td> <td> 0.418</td> <td>   -0.306</td> <td>    0.127</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>대비_국고_3Y</th>         <td>   -0.1891</td> <td>    0.092</td> <td>   -2.065</td> <td> 0.039</td> <td>   -0.369</td> <td>   -0.010</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>대비_국고_5Y</th>         <td>   -0.0052</td> <td>    0.198</td> <td>   -0.026</td> <td> 0.979</td> <td>   -0.393</td> <td>    0.383</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>대비_국고_10Y</th>        <td>   -0.0347</td> <td>    0.181</td> <td>   -0.191</td> <td> 0.848</td> <td>   -0.391</td> <td>    0.321</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>대비_통안_2Y</th>         <td>    0.0339</td> <td>    0.087</td> <td>    0.391</td> <td> 0.696</td> <td>   -0.136</td> <td>    0.204</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>스왑포인트_1M</th>         <td>   -1.1893</td> <td>    0.092</td> <td>  -12.969</td> <td> 0.000</td> <td>   -1.369</td> <td>   -1.009</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>전일종가_ex</th>          <td>   55.7335</td> <td>    0.090</td> <td>  622.289</td> <td> 0.000</td> <td>   55.558</td> <td>   55.909</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>종가_NDF_차이</th>        <td>   -4.0131</td> <td>    0.088</td> <td>  -45.593</td> <td> 0.000</td> <td>   -4.186</td> <td>   -3.840</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td>245.403</td> <th>  Durbin-Watson:     </th> <td>   2.095</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th> <td> 0.000</td>  <th>  Jarque-Bera (JB):  </th> <td>1189.518</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>          <td> 0.353</td>  <th>  Prob(JB):          </th> <td>5.01e-259</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>      <td> 6.333</td>  <th>  Cond. No.          </th> <td>    5.40</td> \n",
       "</tr>\n",
       "</table><br/><br/>Notes:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified."
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                            OLS Regression Results                            \n",
       "==============================================================================\n",
       "Dep. Variable:                  종가_ex   R-squared:                       0.995\n",
       "Model:                            OLS   Adj. R-squared:                  0.995\n",
       "Method:                 Least Squares   F-statistic:                 4.566e+04\n",
       "Date:                Mon, 17 Oct 2022   Prob (F-statistic):               0.00\n",
       "Time:                        17:15:08   Log-Likelihood:                -6937.0\n",
       "No. Observations:                2459   AIC:                         1.390e+04\n",
       "Df Residuals:                    2448   BIC:                         1.396e+04\n",
       "Df Model:                          10                                         \n",
       "Covariance Type:            nonrobust                                         \n",
       "====================================================================================\n",
       "                       coef    std err          t      P>|t|      [0.025      0.975]\n",
       "------------------------------------------------------------------------------------\n",
       "const             1134.8939      0.082   1.38e+04      0.000    1134.733    1135.055\n",
       "대비_swapbasis_1Y     -0.8914      0.107     -8.343      0.000      -1.101      -0.682\n",
       "대비_swapbasis_10Y     0.1240      0.109      1.139      0.255      -0.090       0.337\n",
       "대비_국고_1Y            -0.0895      0.111     -0.809      0.418      -0.306       0.127\n",
       "대비_국고_3Y            -0.1891      0.092     -2.065      0.039      -0.369      -0.010\n",
       "대비_국고_5Y            -0.0052      0.198     -0.026      0.979      -0.393       0.383\n",
       "대비_국고_10Y           -0.0347      0.181     -0.191      0.848      -0.391       0.321\n",
       "대비_통안_2Y             0.0339      0.087      0.391      0.696      -0.136       0.204\n",
       "스왑포인트_1M            -1.1893      0.092    -12.969      0.000      -1.369      -1.009\n",
       "전일종가_ex             55.7335      0.090    622.289      0.000      55.558      55.909\n",
       "종가_NDF_차이           -4.0131      0.088    -45.593      0.000      -4.186      -3.840\n",
       "==============================================================================\n",
       "Omnibus:                      245.403   Durbin-Watson:                   2.095\n",
       "Prob(Omnibus):                  0.000   Jarque-Bera (JB):             1189.518\n",
       "Skew:                           0.353   Prob(JB):                    5.01e-259\n",
       "Kurtosis:                       6.333   Cond. No.                         5.40\n",
       "==============================================================================\n",
       "\n",
       "Notes:\n",
       "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "\"\"\""
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import statsmodels.api as sm\n",
    "\n",
    "feature_add = sm.add_constant(x_scaled, has_constant='add')\n",
    "\n",
    "# sm OLS 적합\n",
    "model = sm.OLS(y , feature_add)\n",
    "fitted_model = model.fit()\n",
    "\n",
    "# summary 함수통해 결과출력\n",
    "fitted_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>          <td>종가_ex</td>      <th>  R-squared:         </th> <td>   0.995</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th> <td>   0.995</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th> <td>5.710e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Mon, 17 Oct 2022</td> <th>  Prob (F-statistic):</th>  <td>  0.00</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>17:15:08</td>     <th>  Log-Likelihood:    </th> <td> -6937.4</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td>  2459</td>      <th>  AIC:               </th> <td>1.389e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td>  2450</td>      <th>  BIC:               </th> <td>1.395e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>     8</td>      <th>                     </th>     <td> </td>    \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>     <td> </td>    \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "          <td></td>            <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>const</th>            <td> 1134.8939</td> <td>    0.082</td> <td> 1.38e+04</td> <td> 0.000</td> <td> 1134.733</td> <td> 1135.055</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>대비_swapbasis_1Y</th>  <td>   -0.8892</td> <td>    0.107</td> <td>   -8.330</td> <td> 0.000</td> <td>   -1.099</td> <td>   -0.680</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>대비_swapbasis_10Y</th> <td>    0.1239</td> <td>    0.109</td> <td>    1.139</td> <td> 0.255</td> <td>   -0.090</td> <td>    0.337</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>대비_국고_3Y</th>         <td>   -0.1984</td> <td>    0.091</td> <td>   -2.190</td> <td> 0.029</td> <td>   -0.376</td> <td>   -0.021</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>대비_국고_5Y</th>         <td>   -0.0488</td> <td>    0.186</td> <td>   -0.262</td> <td> 0.794</td> <td>   -0.414</td> <td>    0.317</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>대비_국고_10Y</th>        <td>   -0.0354</td> <td>    0.181</td> <td>   -0.195</td> <td> 0.846</td> <td>   -0.391</td> <td>    0.320</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>스왑포인트_1M</th>         <td>   -1.1903</td> <td>    0.092</td> <td>  -12.984</td> <td> 0.000</td> <td>   -1.370</td> <td>   -1.010</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>전일종가_ex</th>          <td>   55.7275</td> <td>    0.089</td> <td>  624.695</td> <td> 0.000</td> <td>   55.553</td> <td>   55.902</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>종가_NDF_차이</th>        <td>   -4.0131</td> <td>    0.088</td> <td>  -45.611</td> <td> 0.000</td> <td>   -4.186</td> <td>   -3.841</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td>250.440</td> <th>  Durbin-Watson:     </th> <td>   2.093</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th> <td> 0.000</td>  <th>  Jarque-Bera (JB):  </th> <td>1227.804</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>          <td> 0.362</td>  <th>  Prob(JB):          </th> <td>2.43e-267</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>      <td> 6.385</td>  <th>  Cond. No.          </th> <td>    4.72</td> \n",
       "</tr>\n",
       "</table><br/><br/>Notes:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified."
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                            OLS Regression Results                            \n",
       "==============================================================================\n",
       "Dep. Variable:                  종가_ex   R-squared:                       0.995\n",
       "Model:                            OLS   Adj. R-squared:                  0.995\n",
       "Method:                 Least Squares   F-statistic:                 5.710e+04\n",
       "Date:                Mon, 17 Oct 2022   Prob (F-statistic):               0.00\n",
       "Time:                        17:15:08   Log-Likelihood:                -6937.4\n",
       "No. Observations:                2459   AIC:                         1.389e+04\n",
       "Df Residuals:                    2450   BIC:                         1.395e+04\n",
       "Df Model:                           8                                         \n",
       "Covariance Type:            nonrobust                                         \n",
       "====================================================================================\n",
       "                       coef    std err          t      P>|t|      [0.025      0.975]\n",
       "------------------------------------------------------------------------------------\n",
       "const             1134.8939      0.082   1.38e+04      0.000    1134.733    1135.055\n",
       "대비_swapbasis_1Y     -0.8892      0.107     -8.330      0.000      -1.099      -0.680\n",
       "대비_swapbasis_10Y     0.1239      0.109      1.139      0.255      -0.090       0.337\n",
       "대비_국고_3Y            -0.1984      0.091     -2.190      0.029      -0.376      -0.021\n",
       "대비_국고_5Y            -0.0488      0.186     -0.262      0.794      -0.414       0.317\n",
       "대비_국고_10Y           -0.0354      0.181     -0.195      0.846      -0.391       0.320\n",
       "스왑포인트_1M            -1.1903      0.092    -12.984      0.000      -1.370      -1.010\n",
       "전일종가_ex             55.7275      0.089    624.695      0.000      55.553      55.902\n",
       "종가_NDF_차이           -4.0131      0.088    -45.611      0.000      -4.186      -3.841\n",
       "==============================================================================\n",
       "Omnibus:                      250.440   Durbin-Watson:                   2.093\n",
       "Prob(Omnibus):                  0.000   Jarque-Bera (JB):             1227.804\n",
       "Skew:                           0.362   Prob(JB):                    2.43e-267\n",
       "Kurtosis:                       6.385   Cond. No.                         4.72\n",
       "==============================================================================\n",
       "\n",
       "Notes:\n",
       "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "\"\"\""
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_scaled.drop(['대비_통안_2Y','대비_국고_1Y' ], axis=1, inplace=True)\n",
    "\n",
    "feature_add = sm.add_constant(x_scaled, has_constant='add')\n",
    "\n",
    "# sm OLS 적합\n",
    "model = sm.OLS(y , feature_add)\n",
    "fitted_model = model.fit()\n",
    "\n",
    "# summary 함수통해 결과출력\n",
    "fitted_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>          <td>종가_ex</td>      <th>  R-squared:         </th> <td>   0.995</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th> <td>   0.995</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th> <td>6.529e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Mon, 17 Oct 2022</td> <th>  Prob (F-statistic):</th>  <td>  0.00</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>17:15:09</td>     <th>  Log-Likelihood:    </th> <td> -6937.4</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td>  2459</td>      <th>  AIC:               </th> <td>1.389e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td>  2451</td>      <th>  BIC:               </th> <td>1.394e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>     7</td>      <th>                     </th>     <td> </td>    \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>     <td> </td>    \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "          <td></td>            <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>const</th>            <td> 1134.8939</td> <td>    0.082</td> <td> 1.38e+04</td> <td> 0.000</td> <td> 1134.733</td> <td> 1135.055</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>대비_swapbasis_1Y</th>  <td>   -0.8903</td> <td>    0.107</td> <td>   -8.352</td> <td> 0.000</td> <td>   -1.099</td> <td>   -0.681</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>대비_swapbasis_10Y</th> <td>    0.1255</td> <td>    0.108</td> <td>    1.157</td> <td> 0.247</td> <td>   -0.087</td> <td>    0.338</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>대비_국고_3Y</th>         <td>   -0.1980</td> <td>    0.091</td> <td>   -2.188</td> <td> 0.029</td> <td>   -0.376</td> <td>   -0.021</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>대비_국고_5Y</th>         <td>   -0.0802</td> <td>    0.094</td> <td>   -0.857</td> <td> 0.391</td> <td>   -0.264</td> <td>    0.103</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>스왑포인트_1M</th>         <td>   -1.1902</td> <td>    0.092</td> <td>  -12.986</td> <td> 0.000</td> <td>   -1.370</td> <td>   -1.011</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>전일종가_ex</th>          <td>   55.7276</td> <td>    0.089</td> <td>  624.823</td> <td> 0.000</td> <td>   55.553</td> <td>   55.903</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>종가_NDF_차이</th>        <td>   -4.0136</td> <td>    0.088</td> <td>  -45.644</td> <td> 0.000</td> <td>   -4.186</td> <td>   -3.841</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td>250.759</td> <th>  Durbin-Watson:     </th> <td>   2.093</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th> <td> 0.000</td>  <th>  Jarque-Bera (JB):  </th> <td>1231.080</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>          <td> 0.362</td>  <th>  Prob(JB):          </th> <td>4.73e-268</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>      <td> 6.390</td>  <th>  Cond. No.          </th> <td>    2.33</td> \n",
       "</tr>\n",
       "</table><br/><br/>Notes:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified."
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                            OLS Regression Results                            \n",
       "==============================================================================\n",
       "Dep. Variable:                  종가_ex   R-squared:                       0.995\n",
       "Model:                            OLS   Adj. R-squared:                  0.995\n",
       "Method:                 Least Squares   F-statistic:                 6.529e+04\n",
       "Date:                Mon, 17 Oct 2022   Prob (F-statistic):               0.00\n",
       "Time:                        17:15:09   Log-Likelihood:                -6937.4\n",
       "No. Observations:                2459   AIC:                         1.389e+04\n",
       "Df Residuals:                    2451   BIC:                         1.394e+04\n",
       "Df Model:                           7                                         \n",
       "Covariance Type:            nonrobust                                         \n",
       "====================================================================================\n",
       "                       coef    std err          t      P>|t|      [0.025      0.975]\n",
       "------------------------------------------------------------------------------------\n",
       "const             1134.8939      0.082   1.38e+04      0.000    1134.733    1135.055\n",
       "대비_swapbasis_1Y     -0.8903      0.107     -8.352      0.000      -1.099      -0.681\n",
       "대비_swapbasis_10Y     0.1255      0.108      1.157      0.247      -0.087       0.338\n",
       "대비_국고_3Y            -0.1980      0.091     -2.188      0.029      -0.376      -0.021\n",
       "대비_국고_5Y            -0.0802      0.094     -0.857      0.391      -0.264       0.103\n",
       "스왑포인트_1M            -1.1902      0.092    -12.986      0.000      -1.370      -1.011\n",
       "전일종가_ex             55.7276      0.089    624.823      0.000      55.553      55.903\n",
       "종가_NDF_차이           -4.0136      0.088    -45.644      0.000      -4.186      -3.841\n",
       "==============================================================================\n",
       "Omnibus:                      250.759   Durbin-Watson:                   2.093\n",
       "Prob(Omnibus):                  0.000   Jarque-Bera (JB):             1231.080\n",
       "Skew:                           0.362   Prob(JB):                    4.73e-268\n",
       "Kurtosis:                       6.390   Cond. No.                         2.33\n",
       "==============================================================================\n",
       "\n",
       "Notes:\n",
       "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "\"\"\""
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_scaled.drop(['대비_국고_10Y'], axis=1, inplace=True)\n",
    "\n",
    "feature_add = sm.add_constant(x_scaled, has_constant='add')\n",
    "\n",
    "# sm OLS 적합\n",
    "model = sm.OLS(y , feature_add)\n",
    "fitted_model = model.fit()\n",
    "\n",
    "# summary 함수통해 결과출력\n",
    "fitted_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>          <td>종가_ex</td>      <th>  R-squared:         </th> <td>   0.995</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th> <td>   0.995</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th> <td>7.616e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Mon, 17 Oct 2022</td> <th>  Prob (F-statistic):</th>  <td>  0.00</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>17:15:10</td>     <th>  Log-Likelihood:    </th> <td> -6938.1</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td>  2459</td>      <th>  AIC:               </th> <td>1.389e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td>  2452</td>      <th>  BIC:               </th> <td>1.393e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>     6</td>      <th>                     </th>     <td> </td>    \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>     <td> </td>    \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "         <td></td>            <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>const</th>           <td> 1134.8939</td> <td>    0.082</td> <td> 1.38e+04</td> <td> 0.000</td> <td> 1134.733</td> <td> 1135.055</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>대비_swapbasis_1Y</th> <td>   -0.8133</td> <td>    0.083</td> <td>   -9.764</td> <td> 0.000</td> <td>   -0.977</td> <td>   -0.650</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>대비_국고_3Y</th>        <td>   -0.1967</td> <td>    0.091</td> <td>   -2.173</td> <td> 0.030</td> <td>   -0.374</td> <td>   -0.019</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>대비_국고_5Y</th>        <td>   -0.1034</td> <td>    0.091</td> <td>   -1.132</td> <td> 0.258</td> <td>   -0.283</td> <td>    0.076</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>스왑포인트_1M</th>        <td>   -1.1922</td> <td>    0.092</td> <td>  -13.008</td> <td> 0.000</td> <td>   -1.372</td> <td>   -1.012</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>전일종가_ex</th>         <td>   55.7264</td> <td>    0.089</td> <td>  624.808</td> <td> 0.000</td> <td>   55.552</td> <td>   55.901</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>종가_NDF_차이</th>       <td>   -4.0161</td> <td>    0.088</td> <td>  -45.683</td> <td> 0.000</td> <td>   -4.188</td> <td>   -3.844</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td>251.487</td> <th>  Durbin-Watson:     </th> <td>   2.097</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th> <td> 0.000</td>  <th>  Jarque-Bera (JB):  </th> <td>1235.400</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>          <td> 0.364</td>  <th>  Prob(JB):          </th> <td>5.45e-269</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>      <td> 6.395</td>  <th>  Cond. No.          </th> <td>    1.71</td> \n",
       "</tr>\n",
       "</table><br/><br/>Notes:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified."
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                            OLS Regression Results                            \n",
       "==============================================================================\n",
       "Dep. Variable:                  종가_ex   R-squared:                       0.995\n",
       "Model:                            OLS   Adj. R-squared:                  0.995\n",
       "Method:                 Least Squares   F-statistic:                 7.616e+04\n",
       "Date:                Mon, 17 Oct 2022   Prob (F-statistic):               0.00\n",
       "Time:                        17:15:10   Log-Likelihood:                -6938.1\n",
       "No. Observations:                2459   AIC:                         1.389e+04\n",
       "Df Residuals:                    2452   BIC:                         1.393e+04\n",
       "Df Model:                           6                                         \n",
       "Covariance Type:            nonrobust                                         \n",
       "===================================================================================\n",
       "                      coef    std err          t      P>|t|      [0.025      0.975]\n",
       "-----------------------------------------------------------------------------------\n",
       "const            1134.8939      0.082   1.38e+04      0.000    1134.733    1135.055\n",
       "대비_swapbasis_1Y    -0.8133      0.083     -9.764      0.000      -0.977      -0.650\n",
       "대비_국고_3Y           -0.1967      0.091     -2.173      0.030      -0.374      -0.019\n",
       "대비_국고_5Y           -0.1034      0.091     -1.132      0.258      -0.283       0.076\n",
       "스왑포인트_1M           -1.1922      0.092    -13.008      0.000      -1.372      -1.012\n",
       "전일종가_ex            55.7264      0.089    624.808      0.000      55.552      55.901\n",
       "종가_NDF_차이          -4.0161      0.088    -45.683      0.000      -4.188      -3.844\n",
       "==============================================================================\n",
       "Omnibus:                      251.487   Durbin-Watson:                   2.097\n",
       "Prob(Omnibus):                  0.000   Jarque-Bera (JB):             1235.400\n",
       "Skew:                           0.364   Prob(JB):                    5.45e-269\n",
       "Kurtosis:                       6.395   Cond. No.                         1.71\n",
       "==============================================================================\n",
       "\n",
       "Notes:\n",
       "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "\"\"\""
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_scaled.drop(['대비_swapbasis_10Y'], axis=1, inplace=True)\n",
    "\n",
    "feature_add = sm.add_constant(x_scaled, has_constant='add')\n",
    "\n",
    "# sm OLS 적합\n",
    "model = sm.OLS(y , feature_add)\n",
    "fitted_model = model.fit()\n",
    "\n",
    "# summary 함수통해 결과출력\n",
    "fitted_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>대비_swapbasis_1Y</th>\n",
       "      <th>대비_국고_3Y</th>\n",
       "      <th>대비_국고_5Y</th>\n",
       "      <th>스왑포인트_1M</th>\n",
       "      <th>전일종가_ex</th>\n",
       "      <th>종가_NDF_차이</th>\n",
       "      <th>종가_ex</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DateTime</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2012-08-02</th>\n",
       "      <td>0.348741</td>\n",
       "      <td>-0.646622</td>\n",
       "      <td>-1.079749</td>\n",
       "      <td>1.909409</td>\n",
       "      <td>-0.149841</td>\n",
       "      <td>-1.648743</td>\n",
       "      <td>1131.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2012-08-03</th>\n",
       "      <td>0.348741</td>\n",
       "      <td>-0.323869</td>\n",
       "      <td>-1.890219</td>\n",
       "      <td>1.818881</td>\n",
       "      <td>-0.056232</td>\n",
       "      <td>-1.366022</td>\n",
       "      <td>1134.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2012-08-06</th>\n",
       "      <td>-0.350946</td>\n",
       "      <td>0.160261</td>\n",
       "      <td>0.000879</td>\n",
       "      <td>1.818881</td>\n",
       "      <td>-0.000426</td>\n",
       "      <td>1.602547</td>\n",
       "      <td>1129.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2012-08-07</th>\n",
       "      <td>0.173819</td>\n",
       "      <td>-0.001116</td>\n",
       "      <td>0.000879</td>\n",
       "      <td>1.909409</td>\n",
       "      <td>-0.104837</td>\n",
       "      <td>0.118263</td>\n",
       "      <td>1128.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2012-08-08</th>\n",
       "      <td>-0.001103</td>\n",
       "      <td>-0.323869</td>\n",
       "      <td>-0.539435</td>\n",
       "      <td>1.818881</td>\n",
       "      <td>-0.108437</td>\n",
       "      <td>-0.223358</td>\n",
       "      <td>1128.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-07-25</th>\n",
       "      <td>-0.700790</td>\n",
       "      <td>-0.969375</td>\n",
       "      <td>-1.890219</td>\n",
       "      <td>-0.896960</td>\n",
       "      <td>3.207485</td>\n",
       "      <td>0.860405</td>\n",
       "      <td>1313.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-07-26</th>\n",
       "      <td>0.348741</td>\n",
       "      <td>-0.485246</td>\n",
       "      <td>-0.539435</td>\n",
       "      <td>-0.987488</td>\n",
       "      <td>3.220086</td>\n",
       "      <td>0.754385</td>\n",
       "      <td>1307.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-07-27</th>\n",
       "      <td>0.348741</td>\n",
       "      <td>-0.485246</td>\n",
       "      <td>-1.349905</td>\n",
       "      <td>-0.851696</td>\n",
       "      <td>3.110275</td>\n",
       "      <td>-0.564979</td>\n",
       "      <td>1313.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-07-28</th>\n",
       "      <td>0.173819</td>\n",
       "      <td>0.644391</td>\n",
       "      <td>0.811350</td>\n",
       "      <td>-0.942224</td>\n",
       "      <td>3.212885</td>\n",
       "      <td>1.838148</td>\n",
       "      <td>1296.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-07-29</th>\n",
       "      <td>-0.700790</td>\n",
       "      <td>-2.099012</td>\n",
       "      <td>-3.241004</td>\n",
       "      <td>-0.896960</td>\n",
       "      <td>2.903255</td>\n",
       "      <td>0.200723</td>\n",
       "      <td>1299.1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2459 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            대비_swapbasis_1Y  대비_국고_3Y  대비_국고_5Y  스왑포인트_1M   전일종가_ex  \\\n",
       "DateTime                                                              \n",
       "2012-08-02         0.348741 -0.646622 -1.079749  1.909409 -0.149841   \n",
       "2012-08-03         0.348741 -0.323869 -1.890219  1.818881 -0.056232   \n",
       "2012-08-06        -0.350946  0.160261  0.000879  1.818881 -0.000426   \n",
       "2012-08-07         0.173819 -0.001116  0.000879  1.909409 -0.104837   \n",
       "2012-08-08        -0.001103 -0.323869 -0.539435  1.818881 -0.108437   \n",
       "...                     ...       ...       ...       ...       ...   \n",
       "2022-07-25        -0.700790 -0.969375 -1.890219 -0.896960  3.207485   \n",
       "2022-07-26         0.348741 -0.485246 -0.539435 -0.987488  3.220086   \n",
       "2022-07-27         0.348741 -0.485246 -1.349905 -0.851696  3.110275   \n",
       "2022-07-28         0.173819  0.644391  0.811350 -0.942224  3.212885   \n",
       "2022-07-29        -0.700790 -2.099012 -3.241004 -0.896960  2.903255   \n",
       "\n",
       "            종가_NDF_차이   종가_ex  \n",
       "DateTime                       \n",
       "2012-08-02  -1.648743  1131.7  \n",
       "2012-08-03  -1.366022  1134.8  \n",
       "2012-08-06   1.602547  1129.0  \n",
       "2012-08-07   0.118263  1128.8  \n",
       "2012-08-08  -0.223358  1128.3  \n",
       "...               ...     ...  \n",
       "2022-07-25   0.860405  1313.7  \n",
       "2022-07-26   0.754385  1307.6  \n",
       "2022-07-27  -0.564979  1313.3  \n",
       "2022-07-28   1.838148  1296.1  \n",
       "2022-07-29   0.200723  1299.1  \n",
       "\n",
       "[2459 rows x 7 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_scaled = pd.concat([x_scaled,y], axis=1)\n",
    "df_scaled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = df_scaled[0:1945]\n",
    "test = df_scaled[1945:]\n",
    "\n",
    "def make_dataset(data, label, window_size=5):\n",
    "    feature_list = []\n",
    "    label_list = []\n",
    "    for i in range(len(data) - window_size):\n",
    "        feature_list.append(np.array(data.iloc[i:i+window_size]))\n",
    "        label_list.append(np.array(label.iloc[i+window_size]))\n",
    "    return np.array(feature_list), np.array(label_list)\n",
    "\n",
    "feature_cols = ['대비_swapbasis_1Y', '대비_국고_3Y', '대비_국고_5Y', '스왑포인트_1M', '전일종가_ex', '종가_NDF_차이']\n",
    "label_cols = ['종가_ex']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1552, 5, 6), (388, 5, 6))"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train_feature = train[feature_cols]\n",
    "train_label = train[label_cols]\n",
    "test_feature = test[feature_cols]\n",
    "test_label = test[label_cols]\n",
    "\n",
    "train_feature, train_label = make_dataset(train_feature, train_label, 5)\n",
    "x_train, x_valid, y_train, y_valid = train_test_split(train_feature, train_label, test_size=0.2)\n",
    "x_train.shape, x_valid.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[-8.75711778e-01, -1.62492286e-01,  2.71035799e-01,\n",
       "         -1.57592011e+00,  1.00947158e+00,  9.54645189e-01],\n",
       "        [-1.76024434e-01, -1.11565786e-03, -2.69277966e-01,\n",
       "         -1.44012809e+00,  8.51056207e-01,  9.42865153e-01],\n",
       "        [-1.76024434e-01, -4.85245543e-01, -8.09591731e-01,\n",
       "         -1.44012809e+00,  8.63657430e-01,  1.48474680e+00],\n",
       "        [ 3.48741074e-01, -1.62492286e-01,  8.78916251e-04,\n",
       "         -1.44012809e+00,  7.88050091e-01,  3.65643400e-01],\n",
       "        [ 8.73506582e-01, -1.11565786e-03,  2.71035799e-01,\n",
       "         -1.44012809e+00,  8.38454984e-01,  1.65382792e-01]],\n",
       "\n",
       "       [[ 6.98584746e-01,  3.21637599e-01,  5.41192681e-01,\n",
       "          1.32097643e+00, -2.47050370e-01,  2.40223625e-02],\n",
       "        [ 3.48741074e-01, -3.23868914e-01, -8.09591731e-01,\n",
       "          1.23044841e+00, -3.35258931e-01, -7.02179237e-02],\n",
       "        [-1.76024434e-01, -4.85245543e-01, -1.34990550e+00,\n",
       "          1.27571242e+00, -4.21667318e-01, -8.71260357e-01],\n",
       "        [-1.76024434e-01, -3.23868914e-01, -5.39434849e-01,\n",
       "          1.27571242e+00, -4.01865396e-01, -5.59089409e-01],\n",
       "        [ 3.48741074e-01,  1.60260970e-01,  8.78916251e-04,\n",
       "          1.27571242e+00, -3.78463125e-01,  7.11425056e-02]],\n",
       "\n",
       "       [[-3.50946270e-01, -1.11565786e-03, -2.69277966e-01,\n",
       "          8.23072336e-01,  7.98851140e-01, -1.30712168e+00],\n",
       "        [-3.50946270e-01,  1.60260970e-01,  5.41192681e-01,\n",
       "          7.77808327e-01,  1.01487211e+00, -9.06600464e-01],\n",
       "        [ 3.48741074e-01, -1.62492286e-01, -8.09591731e-01,\n",
       "          7.77808327e-01,  1.03827438e+00,  1.06482613e-01],\n",
       "        [-1.76024434e-01, -8.07998799e-01, -1.89021926e+00,\n",
       "          9.13600353e-01,  1.07787822e+00, -6.59219713e-01],\n",
       "        [ 6.98584746e-01,  4.83014227e-01,  1.35166333e+00,\n",
       "          8.23072336e-01,  9.08661797e-01, -2.82258568e-01]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[-3.50946270e-01, -1.11565786e-03,  2.71035799e-01,\n",
       "         -1.07801602e+00, -1.15433843e+00,  3.89203472e-01],\n",
       "        [-7.00789942e-01,  4.83014227e-01,  5.41192681e-01,\n",
       "         -1.12328003e+00, -1.24074681e+00, -1.88018282e-01],\n",
       "        [-1.22555545e+00, -1.62492286e-01,  8.78916251e-04,\n",
       "         -1.21380804e+00, -1.16513948e+00,  7.07264438e-01],\n",
       "        [-3.50946270e-01, -1.11565786e-03, -2.69277966e-01,\n",
       "         -1.21380804e+00, -1.16333930e+00, -4.94299212e-01],\n",
       "        [ 3.48741074e-01,  3.21637599e-01,  5.41192681e-01,\n",
       "         -1.12328003e+00, -1.16333930e+00,  1.54364698e+00]],\n",
       "\n",
       "       [[-3.50946270e-01,  4.83014227e-01,  2.71035799e-01,\n",
       "         -5.34847918e-01, -8.89712744e-01,  4.59883686e-01],\n",
       "        [-1.76024434e-01, -1.62492286e-01,  8.78916251e-04,\n",
       "         -5.34847918e-01, -8.89712744e-01,  1.77162828e-01],\n",
       "        [-1.10259799e-03, -6.46622171e-01, -1.34990550e+00,\n",
       "         -5.80111926e-01, -8.32107153e-01, -5.76759462e-01],\n",
       "        [ 1.73819238e-01, -1.11565786e-03,  8.78916251e-04,\n",
       "         -5.34847918e-01, -9.07714491e-01,  2.59623078e-01],\n",
       "        [-3.50946270e-01, -6.46622171e-01, -2.69277966e-01,\n",
       "         -5.80111926e-01, -1.04452777e+00, -1.02440082e+00]],\n",
       "\n",
       "       [[-5.25868106e-01, -1.62492286e-01, -2.69277966e-01,\n",
       "         -6.70639943e-01,  2.22795231e-01,  5.18783865e-01],\n",
       "        [-1.76024434e-01,  3.21637599e-01,  8.11349564e-01,\n",
       "         -7.61167960e-01,  1.97592785e-01, -1.10686107e+00],\n",
       "        [ 1.73819238e-01, -1.11565786e-03,  8.78916251e-04,\n",
       "         -8.06431968e-01,  2.84001171e-01,  1.20202594e+00],\n",
       "        [-1.10259799e-03, -1.62492286e-01, -5.39434849e-01,\n",
       "         -7.61167960e-01,  3.09203617e-01,  7.07264438e-01],\n",
       "        [-5.25868106e-01,  1.60260970e-01,  8.78916251e-04,\n",
       "         -7.61167960e-01,  4.63781084e-02, -2.23358389e-01]]])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((509, 5, 6), (509, 1))"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_feature, test_label = make_dataset(test_feature, test_label, 5)\n",
    "test_feature.shape, test_label.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "95/97 [============================>.] - ETA: 0s - loss: 1264392.8750 - mae: 1123.3119\n",
      "Epoch 1: val_loss improved from inf to 1253625.25000, saving model to .\\\n",
      "INFO:tensorflow:Assets written to: .\\assets\n",
      "97/97 [==============================] - 8s 58ms/step - loss: 1263676.0000 - mae: 1122.9980 - val_loss: 1253625.2500 - val_mae: 1118.6650\n",
      "Epoch 2/200\n",
      "96/97 [============================>.] - ETA: 0s - loss: 931922.9375 - mae: 923.2858\n",
      "Epoch 2: val_loss improved from 1253625.25000 to 473095.09375, saving model to .\\\n",
      "INFO:tensorflow:Assets written to: .\\assets\n",
      "97/97 [==============================] - 8s 82ms/step - loss: 926858.5000 - mae: 919.9393 - val_loss: 473095.0938 - val_mae: 605.5435\n",
      "Epoch 3/200\n",
      "91/97 [===========================>..] - ETA: 0s - loss: 255786.2656 - mae: 405.5946\n",
      "Epoch 3: val_loss improved from 473095.09375 to 195910.04688, saving model to .\\\n",
      "INFO:tensorflow:Assets written to: .\\assets\n",
      "97/97 [==============================] - 7s 75ms/step - loss: 247268.0156 - mae: 397.8987 - val_loss: 195910.0469 - val_mae: 310.5717\n",
      "Epoch 4/200\n",
      "92/97 [===========================>..] - ETA: 0s - loss: 115884.1172 - mae: 265.4521\n",
      "Epoch 4: val_loss improved from 195910.04688 to 122000.05469, saving model to .\\\n",
      "INFO:tensorflow:Assets written to: .\\assets\n",
      "97/97 [==============================] - 8s 80ms/step - loss: 114314.3203 - mae: 263.8677 - val_loss: 122000.0547 - val_mae: 231.9370\n",
      "Epoch 5/200\n",
      "89/97 [==========================>...] - ETA: 0s - loss: 71761.9453 - mae: 205.0535\n",
      "Epoch 5: val_loss improved from 122000.05469 to 76938.24219, saving model to .\\\n",
      "INFO:tensorflow:Assets written to: .\\assets\n",
      "97/97 [==============================] - 7s 70ms/step - loss: 70321.1719 - mae: 203.0708 - val_loss: 76938.2422 - val_mae: 187.2202\n",
      "Epoch 6/200\n",
      "93/97 [===========================>..] - ETA: 0s - loss: 45724.6172 - mae: 164.3878\n",
      "Epoch 6: val_loss improved from 76938.24219 to 51652.62500, saving model to .\\\n",
      "INFO:tensorflow:Assets written to: .\\assets\n",
      "97/97 [==============================] - 7s 71ms/step - loss: 45340.0859 - mae: 163.4523 - val_loss: 51652.6250 - val_mae: 147.8207\n",
      "Epoch 7/200\n",
      "88/97 [==========================>...] - ETA: 0s - loss: 30440.8828 - mae: 131.6705\n",
      "Epoch 7: val_loss improved from 51652.62500 to 36372.26172, saving model to .\\\n",
      "INFO:tensorflow:Assets written to: .\\assets\n",
      "97/97 [==============================] - 6s 64ms/step - loss: 30040.0645 - mae: 131.5261 - val_loss: 36372.2617 - val_mae: 124.4088\n",
      "Epoch 8/200\n",
      "93/97 [===========================>..] - ETA: 0s - loss: 20986.4023 - mae: 109.6733\n",
      "Epoch 8: val_loss improved from 36372.26172 to 27081.87109, saving model to .\\\n",
      "INFO:tensorflow:Assets written to: .\\assets\n",
      "97/97 [==============================] - 6s 67ms/step - loss: 20836.0781 - mae: 109.5022 - val_loss: 27081.8711 - val_mae: 111.1115\n",
      "Epoch 9/200\n",
      "96/97 [============================>.] - ETA: 0s - loss: 15112.6953 - mae: 92.8210\n",
      "Epoch 9: val_loss improved from 27081.87109 to 19055.00195, saving model to .\\\n",
      "INFO:tensorflow:Assets written to: .\\assets\n",
      "97/97 [==============================] - 7s 75ms/step - loss: 15037.8945 - mae: 92.5418 - val_loss: 19055.0020 - val_mae: 84.4120\n",
      "Epoch 10/200\n",
      "96/97 [============================>.] - ETA: 0s - loss: 10835.6543 - mae: 77.6941\n",
      "Epoch 10: val_loss improved from 19055.00195 to 14087.14551, saving model to .\\\n",
      "INFO:tensorflow:Assets written to: .\\assets\n",
      "97/97 [==============================] - 8s 84ms/step - loss: 10799.7529 - mae: 77.6510 - val_loss: 14087.1455 - val_mae: 78.1151\n",
      "Epoch 11/200\n",
      "94/97 [============================>.] - ETA: 0s - loss: 8159.6226 - mae: 67.5026\n",
      "Epoch 11: val_loss improved from 14087.14551 to 11214.51172, saving model to .\\\n",
      "INFO:tensorflow:Assets written to: .\\assets\n",
      "97/97 [==============================] - 8s 80ms/step - loss: 8042.1250 - mae: 67.0267 - val_loss: 11214.5117 - val_mae: 66.4353\n",
      "Epoch 12/200\n",
      "97/97 [==============================] - ETA: 0s - loss: 6160.3545 - mae: 58.7669\n",
      "Epoch 12: val_loss improved from 11214.51172 to 8655.68262, saving model to .\\\n",
      "INFO:tensorflow:Assets written to: .\\assets\n",
      "97/97 [==============================] - 7s 73ms/step - loss: 6160.3545 - mae: 58.7669 - val_loss: 8655.6826 - val_mae: 64.4183\n",
      "Epoch 13/200\n",
      "94/97 [============================>.] - ETA: 0s - loss: 4807.4629 - mae: 51.8701\n",
      "Epoch 13: val_loss improved from 8655.68262 to 6551.24414, saving model to .\\\n",
      "INFO:tensorflow:Assets written to: .\\assets\n",
      "97/97 [==============================] - 5s 57ms/step - loss: 4766.5972 - mae: 51.7789 - val_loss: 6551.2441 - val_mae: 54.6242\n",
      "Epoch 14/200\n",
      "93/97 [===========================>..] - ETA: 0s - loss: 3931.5974 - mae: 46.5476\n",
      "Epoch 14: val_loss improved from 6551.24414 to 5173.51221, saving model to .\\\n",
      "INFO:tensorflow:Assets written to: .\\assets\n",
      "97/97 [==============================] - 8s 82ms/step - loss: 3899.3228 - mae: 46.4547 - val_loss: 5173.5122 - val_mae: 46.4565\n",
      "Epoch 15/200\n",
      "94/97 [============================>.] - ETA: 0s - loss: 3121.8347 - mae: 42.1444\n",
      "Epoch 15: val_loss improved from 5173.51221 to 4424.19092, saving model to .\\\n",
      "INFO:tensorflow:Assets written to: .\\assets\n",
      "97/97 [==============================] - 7s 77ms/step - loss: 3248.1404 - mae: 42.2492 - val_loss: 4424.1909 - val_mae: 42.6138\n",
      "Epoch 16/200\n",
      "95/97 [============================>.] - ETA: 0s - loss: 2699.9219 - mae: 38.3582\n",
      "Epoch 16: val_loss improved from 4424.19092 to 3697.27417, saving model to .\\\n",
      "INFO:tensorflow:Assets written to: .\\assets\n",
      "97/97 [==============================] - 7s 70ms/step - loss: 2707.7598 - mae: 38.5041 - val_loss: 3697.2742 - val_mae: 40.3427\n",
      "Epoch 17/200\n",
      "96/97 [============================>.] - ETA: 0s - loss: 2293.6792 - mae: 35.2599\n",
      "Epoch 17: val_loss improved from 3697.27417 to 3335.88940, saving model to .\\\n",
      "INFO:tensorflow:Assets written to: .\\assets\n",
      "97/97 [==============================] - 6s 67ms/step - loss: 2290.7856 - mae: 35.2944 - val_loss: 3335.8894 - val_mae: 39.1544\n",
      "Epoch 18/200\n",
      "96/97 [============================>.] - ETA: 0s - loss: 1959.8937 - mae: 32.2868\n",
      "Epoch 18: val_loss improved from 3335.88940 to 3039.61670, saving model to .\\\n",
      "INFO:tensorflow:Assets written to: .\\assets\n",
      "97/97 [==============================] - 7s 78ms/step - loss: 1958.1763 - mae: 32.3119 - val_loss: 3039.6167 - val_mae: 37.3688\n",
      "Epoch 19/200\n",
      "97/97 [==============================] - ETA: 0s - loss: 1738.4536 - mae: 30.6900\n",
      "Epoch 19: val_loss improved from 3039.61670 to 2622.20532, saving model to .\\\n",
      "INFO:tensorflow:Assets written to: .\\assets\n",
      "97/97 [==============================] - 8s 82ms/step - loss: 1738.4536 - mae: 30.6900 - val_loss: 2622.2053 - val_mae: 32.9856\n",
      "Epoch 20/200\n",
      "92/97 [===========================>..] - ETA: 0s - loss: 1509.3772 - mae: 28.6477\n",
      "Epoch 20: val_loss improved from 2622.20532 to 2368.88672, saving model to .\\\n",
      "INFO:tensorflow:Assets written to: .\\assets\n",
      "97/97 [==============================] - 8s 80ms/step - loss: 1549.7705 - mae: 28.9581 - val_loss: 2368.8867 - val_mae: 30.5999\n",
      "Epoch 21/200\n",
      "97/97 [==============================] - ETA: 0s - loss: 1338.6973 - mae: 26.7565\n",
      "Epoch 21: val_loss improved from 2368.88672 to 2169.10669, saving model to .\\\n",
      "INFO:tensorflow:Assets written to: .\\assets\n",
      "97/97 [==============================] - 7s 74ms/step - loss: 1338.6973 - mae: 26.7565 - val_loss: 2169.1067 - val_mae: 27.8714\n",
      "Epoch 22/200\n",
      "93/97 [===========================>..] - ETA: 0s - loss: 1217.2469 - mae: 25.4330\n",
      "Epoch 22: val_loss improved from 2169.10669 to 2043.57166, saving model to .\\\n",
      "INFO:tensorflow:Assets written to: .\\assets\n",
      "97/97 [==============================] - 7s 69ms/step - loss: 1203.5667 - mae: 25.3546 - val_loss: 2043.5717 - val_mae: 26.8930\n",
      "Epoch 23/200\n",
      "96/97 [============================>.] - ETA: 0s - loss: 1085.7059 - mae: 24.1683\n",
      "Epoch 23: val_loss improved from 2043.57166 to 1875.22119, saving model to .\\\n",
      "INFO:tensorflow:Assets written to: .\\assets\n",
      "97/97 [==============================] - 7s 75ms/step - loss: 1084.2396 - mae: 24.1604 - val_loss: 1875.2212 - val_mae: 24.9298\n",
      "Epoch 24/200\n",
      "91/97 [===========================>..] - ETA: 0s - loss: 998.5659 - mae: 23.0881 \n",
      "Epoch 24: val_loss improved from 1875.22119 to 1838.87769, saving model to .\\\n",
      "INFO:tensorflow:Assets written to: .\\assets\n",
      "97/97 [==============================] - 8s 81ms/step - loss: 979.3306 - mae: 22.8710 - val_loss: 1838.8777 - val_mae: 24.5750\n",
      "Epoch 25/200\n",
      "95/97 [============================>.] - ETA: 0s - loss: 862.0847 - mae: 21.3436\n",
      "Epoch 25: val_loss improved from 1838.87769 to 1768.39758, saving model to .\\\n",
      "INFO:tensorflow:Assets written to: .\\assets\n",
      "97/97 [==============================] - 8s 80ms/step - loss: 869.3002 - mae: 21.4570 - val_loss: 1768.3976 - val_mae: 24.9292\n",
      "Epoch 26/200\n",
      "94/97 [============================>.] - ETA: 0s - loss: 795.6917 - mae: 20.6456\n",
      "Epoch 26: val_loss improved from 1768.39758 to 1626.10168, saving model to .\\\n",
      "INFO:tensorflow:Assets written to: .\\assets\n",
      "97/97 [==============================] - 9s 94ms/step - loss: 795.2679 - mae: 20.6777 - val_loss: 1626.1017 - val_mae: 22.5707\n",
      "Epoch 27/200\n",
      "94/97 [============================>.] - ETA: 0s - loss: 746.4733 - mae: 19.9504\n",
      "Epoch 27: val_loss improved from 1626.10168 to 1601.55713, saving model to .\\\n",
      "INFO:tensorflow:Assets written to: .\\assets\n",
      "97/97 [==============================] - 8s 81ms/step - loss: 747.5945 - mae: 19.9851 - val_loss: 1601.5571 - val_mae: 22.2068\n",
      "Epoch 28/200\n",
      "96/97 [============================>.] - ETA: 0s - loss: 703.0120 - mae: 19.1927\n",
      "Epoch 28: val_loss improved from 1601.55713 to 1477.85498, saving model to .\\\n",
      "INFO:tensorflow:Assets written to: .\\assets\n",
      "97/97 [==============================] - 7s 74ms/step - loss: 706.6265 - mae: 19.2195 - val_loss: 1477.8550 - val_mae: 20.7092\n",
      "Epoch 29/200\n",
      "95/97 [============================>.] - ETA: 0s - loss: 616.8162 - mae: 18.1002\n",
      "Epoch 29: val_loss improved from 1477.85498 to 1459.53174, saving model to .\\\n",
      "INFO:tensorflow:Assets written to: .\\assets\n",
      "97/97 [==============================] - 7s 77ms/step - loss: 626.4596 - mae: 18.1188 - val_loss: 1459.5317 - val_mae: 20.1321\n",
      "Epoch 30/200\n",
      "91/97 [===========================>..] - ETA: 0s - loss: 578.8530 - mae: 17.3693\n",
      "Epoch 30: val_loss improved from 1459.53174 to 1395.16162, saving model to .\\\n",
      "INFO:tensorflow:Assets written to: .\\assets\n",
      "97/97 [==============================] - 8s 78ms/step - loss: 577.0001 - mae: 17.4480 - val_loss: 1395.1616 - val_mae: 19.7808\n",
      "Epoch 31/200\n",
      "94/97 [============================>.] - ETA: 0s - loss: 561.9613 - mae: 17.2364\n",
      "Epoch 31: val_loss improved from 1395.16162 to 1373.83679, saving model to .\\\n",
      "INFO:tensorflow:Assets written to: .\\assets\n",
      "97/97 [==============================] - 7s 77ms/step - loss: 553.5759 - mae: 17.1359 - val_loss: 1373.8368 - val_mae: 19.1745\n",
      "Epoch 32/200\n",
      "94/97 [============================>.] - ETA: 0s - loss: 523.6241 - mae: 16.6308\n",
      "Epoch 32: val_loss did not improve from 1373.83679\n",
      "97/97 [==============================] - 1s 11ms/step - loss: 522.9222 - mae: 16.5997 - val_loss: 1447.5616 - val_mae: 21.5329\n",
      "Epoch 33/200\n",
      "94/97 [============================>.] - ETA: 0s - loss: 482.7052 - mae: 15.9006\n",
      "Epoch 33: val_loss improved from 1373.83679 to 1281.35522, saving model to .\\\n",
      "INFO:tensorflow:Assets written to: .\\assets\n",
      "97/97 [==============================] - 8s 78ms/step - loss: 479.3164 - mae: 15.9059 - val_loss: 1281.3552 - val_mae: 18.2267\n",
      "Epoch 34/200\n",
      "93/97 [===========================>..] - ETA: 0s - loss: 471.7561 - mae: 15.8102\n",
      "Epoch 34: val_loss improved from 1281.35522 to 1263.38281, saving model to .\\\n",
      "INFO:tensorflow:Assets written to: .\\assets\n",
      "97/97 [==============================] - 7s 77ms/step - loss: 464.6069 - mae: 15.7213 - val_loss: 1263.3828 - val_mae: 17.6211\n",
      "Epoch 35/200\n",
      "90/97 [==========================>...] - ETA: 0s - loss: 439.8710 - mae: 15.2629\n",
      "Epoch 35: val_loss improved from 1263.38281 to 1248.50378, saving model to .\\\n",
      "INFO:tensorflow:Assets written to: .\\assets\n",
      "97/97 [==============================] - 9s 89ms/step - loss: 439.2190 - mae: 15.3335 - val_loss: 1248.5038 - val_mae: 17.3923\n",
      "Epoch 36/200\n",
      "93/97 [===========================>..] - ETA: 0s - loss: 423.8015 - mae: 15.0074\n",
      "Epoch 36: val_loss improved from 1248.50378 to 1224.19421, saving model to .\\\n",
      "INFO:tensorflow:Assets written to: .\\assets\n",
      "97/97 [==============================] - 11s 118ms/step - loss: 422.4961 - mae: 14.9650 - val_loss: 1224.1942 - val_mae: 17.4770\n",
      "Epoch 37/200\n",
      "95/97 [============================>.] - ETA: 0s - loss: 393.3520 - mae: 14.6117\n",
      "Epoch 37: val_loss improved from 1224.19421 to 1216.62793, saving model to .\\\n",
      "INFO:tensorflow:Assets written to: .\\assets\n",
      "97/97 [==============================] - 10s 103ms/step - loss: 394.6081 - mae: 14.6369 - val_loss: 1216.6279 - val_mae: 17.0949\n",
      "Epoch 38/200\n",
      "97/97 [==============================] - ETA: 0s - loss: 367.6209 - mae: 13.9672\n",
      "Epoch 38: val_loss improved from 1216.62793 to 1149.39270, saving model to .\\\n",
      "INFO:tensorflow:Assets written to: .\\assets\n",
      "97/97 [==============================] - 9s 94ms/step - loss: 367.6209 - mae: 13.9672 - val_loss: 1149.3927 - val_mae: 16.2571\n",
      "Epoch 39/200\n",
      "91/97 [===========================>..] - ETA: 0s - loss: 361.4656 - mae: 13.8319\n",
      "Epoch 39: val_loss did not improve from 1149.39270\n",
      "97/97 [==============================] - 1s 9ms/step - loss: 359.2309 - mae: 13.8449 - val_loss: 1155.6135 - val_mae: 16.0360\n",
      "Epoch 40/200\n",
      "96/97 [============================>.] - ETA: 0s - loss: 337.6497 - mae: 13.4751\n",
      "Epoch 40: val_loss improved from 1149.39270 to 1143.84082, saving model to .\\\n",
      "INFO:tensorflow:Assets written to: .\\assets\n",
      "97/97 [==============================] - 11s 110ms/step - loss: 335.6754 - mae: 13.4262 - val_loss: 1143.8408 - val_mae: 15.9337\n",
      "Epoch 41/200\n",
      "90/97 [==========================>...] - ETA: 0s - loss: 343.0941 - mae: 13.5341\n",
      "Epoch 41: val_loss improved from 1143.84082 to 1108.71118, saving model to .\\\n",
      "INFO:tensorflow:Assets written to: .\\assets\n",
      "97/97 [==============================] - 9s 95ms/step - loss: 336.6939 - mae: 13.4436 - val_loss: 1108.7112 - val_mae: 15.4406\n",
      "Epoch 42/200\n",
      "96/97 [============================>.] - ETA: 0s - loss: 312.0717 - mae: 12.9807\n",
      "Epoch 42: val_loss did not improve from 1108.71118\n",
      "97/97 [==============================] - 1s 10ms/step - loss: 311.4417 - mae: 12.9801 - val_loss: 1128.5427 - val_mae: 15.8195\n",
      "Epoch 43/200\n",
      "94/97 [============================>.] - ETA: 0s - loss: 306.5063 - mae: 12.7558\n",
      "Epoch 43: val_loss improved from 1108.71118 to 1095.03296, saving model to .\\\n"
     ]
    },
    {
     "ename": "UnicodeDecodeError",
     "evalue": "'utf-8' codec can't decode byte 0xc1 in position 133: invalid start byte",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mUnicodeDecodeError\u001b[0m                        Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\tlsdm\\OneDrive\\바탕 화면\\신의영\\유비온\\유비온 프로젝트 자료\\프로젝트 1 자료\\코딩\\LSTM_EN_대비(경)B.ipynb 셀 16\u001b[0m in \u001b[0;36m<cell line: 24>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/tlsdm/OneDrive/%EB%B0%94%ED%83%95%20%ED%99%94%EB%A9%B4/%EC%8B%A0%EC%9D%98%EC%98%81/%EC%9C%A0%EB%B9%84%EC%98%A8/%EC%9C%A0%EB%B9%84%EC%98%A8%20%ED%94%84%EB%A1%9C%EC%A0%9D%ED%8A%B8%20%EC%9E%90%EB%A3%8C/%ED%94%84%EB%A1%9C%EC%A0%9D%ED%8A%B8%201%20%EC%9E%90%EB%A3%8C/%EC%BD%94%EB%94%A9/LSTM_EN_%EB%8C%80%EB%B9%84%28%EA%B2%BD%29B.ipynb#X44sZmlsZQ%3D%3D?line=19'>20</a>\u001b[0m checkpoint \u001b[39m=\u001b[39m ModelCheckpoint(filepath\u001b[39m=\u001b[39mmodelpath, monitor\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mval_loss\u001b[39m\u001b[39m'\u001b[39m, verbose\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m, save_best_only\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m, mode\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mauto\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/tlsdm/OneDrive/%EB%B0%94%ED%83%95%20%ED%99%94%EB%A9%B4/%EC%8B%A0%EC%9D%98%EC%98%81/%EC%9C%A0%EB%B9%84%EC%98%A8/%EC%9C%A0%EB%B9%84%EC%98%A8%20%ED%94%84%EB%A1%9C%EC%A0%9D%ED%8A%B8%20%EC%9E%90%EB%A3%8C/%ED%94%84%EB%A1%9C%EC%A0%9D%ED%8A%B8%201%20%EC%9E%90%EB%A3%8C/%EC%BD%94%EB%94%A9/LSTM_EN_%EB%8C%80%EB%B9%84%28%EA%B2%BD%29B.ipynb#X44sZmlsZQ%3D%3D?line=20'>21</a>\u001b[0m \u001b[39m# filename = os.path.join(file_path=model_path, 'tmp_checkpoint.h5')\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/tlsdm/OneDrive/%EB%B0%94%ED%83%95%20%ED%99%94%EB%A9%B4/%EC%8B%A0%EC%9D%98%EC%98%81/%EC%9C%A0%EB%B9%84%EC%98%A8/%EC%9C%A0%EB%B9%84%EC%98%A8%20%ED%94%84%EB%A1%9C%EC%A0%9D%ED%8A%B8%20%EC%9E%90%EB%A3%8C/%ED%94%84%EB%A1%9C%EC%A0%9D%ED%8A%B8%201%20%EC%9E%90%EB%A3%8C/%EC%BD%94%EB%94%A9/LSTM_EN_%EB%8C%80%EB%B9%84%28%EA%B2%BD%29B.ipynb#X44sZmlsZQ%3D%3D?line=21'>22</a>\u001b[0m \n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/tlsdm/OneDrive/%EB%B0%94%ED%83%95%20%ED%99%94%EB%A9%B4/%EC%8B%A0%EC%9D%98%EC%98%81/%EC%9C%A0%EB%B9%84%EC%98%A8/%EC%9C%A0%EB%B9%84%EC%98%A8%20%ED%94%84%EB%A1%9C%EC%A0%9D%ED%8A%B8%20%EC%9E%90%EB%A3%8C/%ED%94%84%EB%A1%9C%EC%A0%9D%ED%8A%B8%201%20%EC%9E%90%EB%A3%8C/%EC%BD%94%EB%94%A9/LSTM_EN_%EB%8C%80%EB%B9%84%28%EA%B2%BD%29B.ipynb#X44sZmlsZQ%3D%3D?line=22'>23</a>\u001b[0m \u001b[39m# 모델의 실행\u001b[39;00m\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/tlsdm/OneDrive/%EB%B0%94%ED%83%95%20%ED%99%94%EB%A9%B4/%EC%8B%A0%EC%9D%98%EC%98%81/%EC%9C%A0%EB%B9%84%EC%98%A8/%EC%9C%A0%EB%B9%84%EC%98%A8%20%ED%94%84%EB%A1%9C%EC%A0%9D%ED%8A%B8%20%EC%9E%90%EB%A3%8C/%ED%94%84%EB%A1%9C%EC%A0%9D%ED%8A%B8%201%20%EC%9E%90%EB%A3%8C/%EC%BD%94%EB%94%A9/LSTM_EN_%EB%8C%80%EB%B9%84%28%EA%B2%BD%29B.ipynb#X44sZmlsZQ%3D%3D?line=23'>24</a>\u001b[0m history \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39;49mfit(x_train, y_train, \n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/tlsdm/OneDrive/%EB%B0%94%ED%83%95%20%ED%99%94%EB%A9%B4/%EC%8B%A0%EC%9D%98%EC%98%81/%EC%9C%A0%EB%B9%84%EC%98%A8/%EC%9C%A0%EB%B9%84%EC%98%A8%20%ED%94%84%EB%A1%9C%EC%A0%9D%ED%8A%B8%20%EC%9E%90%EB%A3%8C/%ED%94%84%EB%A1%9C%EC%A0%9D%ED%8A%B8%201%20%EC%9E%90%EB%A3%8C/%EC%BD%94%EB%94%A9/LSTM_EN_%EB%8C%80%EB%B9%84%28%EA%B2%BD%29B.ipynb#X44sZmlsZQ%3D%3D?line=24'>25</a>\u001b[0m                     epochs\u001b[39m=\u001b[39;49m\u001b[39m200\u001b[39;49m, \n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/tlsdm/OneDrive/%EB%B0%94%ED%83%95%20%ED%99%94%EB%A9%B4/%EC%8B%A0%EC%9D%98%EC%98%81/%EC%9C%A0%EB%B9%84%EC%98%A8/%EC%9C%A0%EB%B9%84%EC%98%A8%20%ED%94%84%EB%A1%9C%EC%A0%9D%ED%8A%B8%20%EC%9E%90%EB%A3%8C/%ED%94%84%EB%A1%9C%EC%A0%9D%ED%8A%B8%201%20%EC%9E%90%EB%A3%8C/%EC%BD%94%EB%94%A9/LSTM_EN_%EB%8C%80%EB%B9%84%28%EA%B2%BD%29B.ipynb#X44sZmlsZQ%3D%3D?line=25'>26</a>\u001b[0m                     batch_size\u001b[39m=\u001b[39;49m\u001b[39m16\u001b[39;49m,\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/tlsdm/OneDrive/%EB%B0%94%ED%83%95%20%ED%99%94%EB%A9%B4/%EC%8B%A0%EC%9D%98%EC%98%81/%EC%9C%A0%EB%B9%84%EC%98%A8/%EC%9C%A0%EB%B9%84%EC%98%A8%20%ED%94%84%EB%A1%9C%EC%A0%9D%ED%8A%B8%20%EC%9E%90%EB%A3%8C/%ED%94%84%EB%A1%9C%EC%A0%9D%ED%8A%B8%201%20%EC%9E%90%EB%A3%8C/%EC%BD%94%EB%94%A9/LSTM_EN_%EB%8C%80%EB%B9%84%28%EA%B2%BD%29B.ipynb#X44sZmlsZQ%3D%3D?line=26'>27</a>\u001b[0m                     validation_data\u001b[39m=\u001b[39;49m(x_valid, y_valid), \n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/tlsdm/OneDrive/%EB%B0%94%ED%83%95%20%ED%99%94%EB%A9%B4/%EC%8B%A0%EC%9D%98%EC%98%81/%EC%9C%A0%EB%B9%84%EC%98%A8/%EC%9C%A0%EB%B9%84%EC%98%A8%20%ED%94%84%EB%A1%9C%EC%A0%9D%ED%8A%B8%20%EC%9E%90%EB%A3%8C/%ED%94%84%EB%A1%9C%EC%A0%9D%ED%8A%B8%201%20%EC%9E%90%EB%A3%8C/%EC%BD%94%EB%94%A9/LSTM_EN_%EB%8C%80%EB%B9%84%28%EA%B2%BD%29B.ipynb#X44sZmlsZQ%3D%3D?line=27'>28</a>\u001b[0m                     callbacks\u001b[39m=\u001b[39;49m[early_stop, checkpoint])\n",
      "File \u001b[1;32mc:\\Users\\tlsdm\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\utils\\traceback_utils.py:67\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     65\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:  \u001b[39m# pylint: disable=broad-except\u001b[39;00m\n\u001b[0;32m     66\u001b[0m   filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n\u001b[1;32m---> 67\u001b[0m   \u001b[39mraise\u001b[39;00m e\u001b[39m.\u001b[39mwith_traceback(filtered_tb) \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39m\n\u001b[0;32m     68\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[0;32m     69\u001b[0m   \u001b[39mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[1;32mc:\\Users\\tlsdm\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py:54\u001b[0m, in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     52\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m     53\u001b[0m   ctx\u001b[39m.\u001b[39mensure_initialized()\n\u001b[1;32m---> 54\u001b[0m   tensors \u001b[39m=\u001b[39m pywrap_tfe\u001b[39m.\u001b[39mTFE_Py_Execute(ctx\u001b[39m.\u001b[39m_handle, device_name, op_name,\n\u001b[0;32m     55\u001b[0m                                       inputs, attrs, num_outputs)\n\u001b[0;32m     56\u001b[0m \u001b[39mexcept\u001b[39;00m core\u001b[39m.\u001b[39m_NotOkStatusException \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m     57\u001b[0m   \u001b[39mif\u001b[39;00m name \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "\u001b[1;31mUnicodeDecodeError\u001b[0m: 'utf-8' codec can't decode byte 0xc1 in position 133: invalid start byte"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from tensorflow.keras.layers import LSTM\n",
    "\n",
    "\n",
    "# 모델의 설정\n",
    "model = Sequential()\n",
    "model.add(LSTM(16, \n",
    "               input_shape=(train_feature.shape[1], train_feature.shape[2]), \n",
    "               activation='relu', \n",
    "               return_sequences=False)\n",
    "          )\n",
    "model.add(Dense(1))\n",
    "\n",
    "# 모델의 컴파일: 모델학습을 위한 학습과정 설정단계\n",
    "model.compile(loss='mean_squared_error', optimizer='adam', metrics=['mae'])\n",
    "early_stop = EarlyStopping(monitor='val_loss', patience=10)\n",
    "modelpath = './'\n",
    "checkpoint = ModelCheckpoint(filepath=modelpath, monitor='val_loss', verbose=1, save_best_only=True, mode='auto')\n",
    "# filename = os.path.join(file_path=model_path, 'tmp_checkpoint.h5')\n",
    "\n",
    "# 모델의 실행\n",
    "history = model.fit(x_train, y_train, \n",
    "                    epochs=200, \n",
    "                    batch_size=16,\n",
    "                    validation_data=(x_valid, y_valid), \n",
    "                    callbacks=[early_stop, checkpoint])\n",
    "\n",
    "# 테스트 정확도 출력                    \n",
    "# print(\"\\n Accuracy: %.4f\" % model.evaluate(x_valid, y_valid)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 0s 2ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x1451e7ca0>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 864x648 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "pred = model.predict(test_feature)\n",
    "\n",
    "import matplotlib.pyplot as plt \n",
    "plt.figure(figsize=(12, 9))\n",
    "plt.plot(test_label, label='actual')\n",
    "plt.plot(pred, label='prediction')\n",
    "plt.grid()\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.0 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "a073e8c3e7241d11bd26aeacf78abcb385fecb9ce1a8fb10ee8efd278424d43e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
